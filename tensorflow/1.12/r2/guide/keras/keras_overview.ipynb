{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_overview.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "CCQY7jpBfMur"
      },
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "z6X9omPnfO_h",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "F1xIRPtY0E1w"
      },
      "cell_type": "markdown",
      "source": [
        "# Keras: a quick overview"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VyOjQZHhZxaA"
      },
      "cell_type": "markdown",
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/alpha/guide/keras/keras_overview\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/r2/guide/keras/keras_overview.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/r2/guide/keras/keras_overview.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "IsK5aF2xZ-40"
      },
      "cell_type": "markdown",
      "source": [
        "## Import tf.keras\n",
        "\n",
        "`tf.keras` is TensorFlow's implementation of the\n",
        "[Keras API specification](https://keras.io){:.external}. This is a high-level\n",
        "API to build and train models that includes first-class support for\n",
        "TensorFlow-specific functionality, such as [eager execution](#eager_execution),\n",
        "`tf.data` pipelines, and [Estimators](./estimators.md).\n",
        "`tf.keras` makes TensorFlow easier to use without sacrificing flexibility and\n",
        "performance.\n",
        "\n",
        "To get started, import `tf.keras` as part of your TensorFlow program setup:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Qoc055N3wiUG",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q pyyaml  # pyyaml is optional"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "TgPcBFru0E1z",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "!pip install tf-nightly-2.0-preview\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "lj03RamP0E13"
      },
      "cell_type": "markdown",
      "source": [
        "`tf.keras` can run any Keras-compatible code, but keep in mind:\n",
        "\n",
        "* The `tf.keras` version in the latest TensorFlow release might not be the same\n",
        "  as the latest `keras` version from PyPI. Check `tf.keras.__version__`.\n",
        "* When [saving a model's weights](#weights_only), `tf.keras` defaults to the\n",
        "  [checkpoint format](./checkpoints.md). Pass `save_format='h5'` to\n",
        "  use HDF5."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "7e1LPcXx0gR6"
      },
      "cell_type": "markdown",
      "source": [
        "## Build a simple model\n",
        "\n",
        "### Sequential model\n",
        "\n",
        "In Keras, you assemble *layers* to build *models*. A model is (usually) a graph\n",
        "of layers. The most common type of model is a stack of layers: the\n",
        "`tf.keras.Sequential` model.\n",
        "\n",
        "To build a simple, fully-connected network (i.e. multi-layer perceptron):"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "WM-DUVQB0E14",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "# Adds a densely-connected layer with 64 units to the model:\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "# Add another:\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "# Add a softmax layer with 10 output units:\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I2oH0-cxH7YA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can find a complete, short example of how to use Sequential models [here](https://github.com/tensorflow/docs/blob/master/site/en/r2/tutorials/quickstart/beginner.ipynb).\n",
        "\n",
        "To learn about building more advanced models than Sequential models, see:\n",
        "- [Guide to the Keras Functional API in TF 2.0](./keras_functional_api_in_tensorflow_2)\n",
        "- [Guide to writing layers and models from scratch with subclassing](./writing_layers_and_models_from_scratch_in_tensorflow_2)"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "-ztyTipu0E18"
      },
      "cell_type": "markdown",
      "source": [
        "### Configure the layers\n",
        "\n",
        "There are many `tf.keras.layers` available with some common constructor\n",
        "parameters:\n",
        "\n",
        "* `activation`: Set the activation function for the layer. This parameter is\n",
        "  specified by the name of a built-in function or as a callable object. By\n",
        "  default, no activation is applied.\n",
        "* `kernel_initializer` and `bias_initializer`: The initialization schemes\n",
        "  that create the layer's weights (kernel and bias). This parameter is a name or\n",
        "  a callable object. This defaults to the `\"Glorot uniform\"` initializer.\n",
        "* `kernel_regularizer` and `bias_regularizer`: The regularization schemes\n",
        "  that apply the layer's weights (kernel and bias), such as L1 or L2\n",
        "  regularization. By default, no regularization is applied.\n",
        "\n",
        "The following instantiates `tf.keras.layers.Dense` layers using constructor\n",
        "arguments:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "MlL7PBtp0E19",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a sigmoid layer:\n",
        "layers.Dense(64, activation='sigmoid')\n",
        "# Or:\n",
        "layers.Dense(64, activation=tf.keras.activations.sigmoid)\n",
        "\n",
        "# A linear layer with L1 regularization of factor 0.01 applied to the kernel matrix:\n",
        "layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1(0.01))\n",
        "\n",
        "# A linear layer with L2 regularization of factor 0.01 applied to the bias vector:\n",
        "layers.Dense(64, bias_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "\n",
        "# A linear layer with a kernel initialized to a random orthogonal matrix:\n",
        "layers.Dense(64, kernel_initializer='orthogonal')\n",
        "\n",
        "# A linear layer with a bias vector initialized to 2.0s:\n",
        "layers.Dense(64, bias_initializer=tf.keras.initializers.Constant(2.0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "9NR6reyk0E2A"
      },
      "cell_type": "markdown",
      "source": [
        "## Train and evaluate\n",
        "\n",
        "### Set up training\n",
        "\n",
        "After the model is constructed, configure its learning process by calling the\n",
        "`compile` method:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "sJ4AOn090E2A",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "# Adds a densely-connected layer with 64 units to the model:\n",
        "layers.Dense(64, activation='relu', input_shape=(32,)),\n",
        "# Add another:\n",
        "layers.Dense(64, activation='relu'),\n",
        "# Add a softmax layer with 10 output units:\n",
        "layers.Dense(10, activation='softmax')])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "HG-RAa9F0E2D"
      },
      "cell_type": "markdown",
      "source": [
        "`tf.keras.Model.compile` takes three important arguments:\n",
        "\n",
        "* `optimizer`: This object specifies the training procedure. Pass it optimizer\n",
        "  instances from the `tf.keras.optimizers` module, such as\n",
        "  `tf.keras.optimizers.Adam` or\n",
        "  `tf.keras.optimizers.SGD`. If you just want to use the default parameters, you can also specify optimizers via strings, such as `'adam'` or `'sgd'`.\n",
        "* `loss`: The function to minimize during optimization. Common choices include\n",
        "  mean square error (`mse`), `categorical_crossentropy`, and\n",
        "  `binary_crossentropy`. Loss functions are specified by name or by\n",
        "  passing a callable object from the `tf.keras.losses` module.\n",
        "* `metrics`: Used to monitor training. These are string names or callables from\n",
        "  the `tf.keras.metrics` module.\n",
        "* Additionally, to make sure the model trains and evaluates eagerly, you can make sure to pass `run_eagerly=True` as a parameter to compile.\n",
        "\n",
        "\n",
        "The following shows a few examples of configuring a model for training:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "St4Mgdar0E2E",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Configure a model for mean-squared error regression.\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "              loss='mse',       # mean squared error\n",
        "              metrics=['mae'])  # mean absolute error\n",
        "\n",
        "# Configure a model for categorical classification.\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.01),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=[tf.keras.metrics.CategoricalAccuracy()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "yjI5rbi80E2G"
      },
      "cell_type": "markdown",
      "source": [
        "### Train from NumPy data\n",
        "\n",
        "For small datasets, use in-memory [NumPy](https://www.numpy.org/){:.external}\n",
        "arrays to train and evaluate a model. The model is \"fit\" to the training data\n",
        "using the `fit` method:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3CvP6L-m0E2I",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "data = np.random.random((1000, 32))\n",
        "labels = np.random.random((1000, 10))\n",
        "\n",
        "model.fit(data, labels, epochs=10, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "N-pnVaFe0E2N"
      },
      "cell_type": "markdown",
      "source": [
        "`tf.keras.Model.fit` takes three important arguments:\n",
        "\n",
        "* `epochs`: Training is structured into *epochs*. An epoch is one iteration over\n",
        "  the entire input data (this is done in smaller batches).\n",
        "* `batch_size`: When passed NumPy data, the model slices the data into smaller\n",
        "  batches and iterates over these batches during training. This integer\n",
        "  specifies the size of each batch. Be aware that the last batch may be smaller\n",
        "  if the total number of samples is not divisible by the batch size.\n",
        "* `validation_data`: When prototyping a model, you want to easily monitor its\n",
        "  performance on some validation data. Passing this argument—a tuple of inputs\n",
        "  and labels—allows the model to display the loss and metrics in inference mode\n",
        "  for the passed data, at the end of each epoch.\n",
        "\n",
        "Here's an example using `validation_data`:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gFcXzVQa0E2N",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "data = np.random.random((1000, 32))\n",
        "labels = np.random.random((1000, 10))\n",
        "\n",
        "val_data = np.random.random((100, 32))\n",
        "val_labels = np.random.random((100, 10))\n",
        "\n",
        "model.fit(data, labels, epochs=10, batch_size=32,\n",
        "          validation_data=(val_data, val_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "-6ImyXzz0E2Q"
      },
      "cell_type": "markdown",
      "source": [
        "### Train from tf.data datasets\n",
        "\n",
        "Use the [Datasets API](./datasets.md) to scale to large datasets\n",
        "or multi-device training. Pass a `tf.data.Dataset` instance to the `fit`\n",
        "method:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "OziqhpIj0E2R",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Instantiates a toy dataset instance:\n",
        "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
        "dataset = dataset.batch(32)\n",
        "dataset = dataset.repeat()\n",
        "\n",
        "# Don't forget to specify `steps_per_epoch` when calling `fit` on a dataset.\n",
        "model.fit(dataset, epochs=10, steps_per_epoch=30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "I7BcMHkB0E2U"
      },
      "cell_type": "markdown",
      "source": [
        "Here, the `fit` method uses the `steps_per_epoch` argument—this is the number of\n",
        "training steps the model runs before it moves to the next epoch. Since the\n",
        "`Dataset` yields batches of data, this snippet does not require a `batch_size`.\n",
        "\n",
        "Datasets can also be used for validation:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "YPMb3A0N0E2V",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
        "dataset = dataset.batch(32).repeat()\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_labels))\n",
        "val_dataset = val_dataset.batch(32).repeat()\n",
        "\n",
        "model.fit(dataset, epochs=10, steps_per_epoch=30,\n",
        "          validation_data=val_dataset,\n",
        "          validation_steps=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "IgGdlXso0E2X"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluate and predict\n",
        "\n",
        "The `tf.keras.Model.evaluate` and `tf.keras.Model.predict` methods can use NumPy\n",
        "data and a `tf.data.Dataset`.\n",
        "\n",
        "To *evaluate* the inference-mode loss and metrics for the data provided:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mhDbOHEK0E2Y",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = np.random.random((1000, 32))\n",
        "labels = np.random.random((1000, 10))\n",
        "\n",
        "model.evaluate(data, labels, batch_size=32)\n",
        "\n",
        "model.evaluate(dataset, steps=30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "UXUTmDfb0E2b"
      },
      "cell_type": "markdown",
      "source": [
        "And to *predict* the output of the last layer in inference for the data provided,\n",
        "as a NumPy array:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9e3JsSoQ0E2c",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "result = model.predict(data, batch_size=32)\n",
        "print(result.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GuTb71gYILLG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For a complete guide on training and evaluation, including how to write custom training loops from sratch, see the [Guide to Training & Evaluation with Keras](./training_and_evaluation_with_keras_in_tensorflow_2)."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "fzEOW4Cn0E2h"
      },
      "cell_type": "markdown",
      "source": [
        "## Build advanced models\n",
        "\n",
        "### Functional API\n",
        "\n",
        " The `tf.keras.Sequential` model is a simple stack of layers that cannot\n",
        "represent arbitrary models. Use the\n",
        "[Keras functional API](./keras_functional_api_in_tensorflow_2)\n",
        "to build complex model topologies such as:\n",
        "\n",
        "* Multi-input models,\n",
        "* Multi-output models,\n",
        "* Models with shared layers (the same layer called several times),\n",
        "* Models with non-sequential data flows (e.g. residual connections).\n",
        "\n",
        "Building a model with the functional API works like this:\n",
        "\n",
        "1. A layer instance is callable and returns a tensor.\n",
        "2. Input tensors and output tensors are used to define a `tf.keras.Model`\n",
        "   instance.\n",
        "3. This model is trained just like the `Sequential` model.\n",
        "\n",
        "The following example uses the functional API to build a simple, fully-connected\n",
        "network:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mROj832r0E2i",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.Input(shape=(32,))  # Returns an input placeholder\n",
        "\n",
        "# A layer instance is callable on a tensor, and returns a tensor.\n",
        "x = layers.Dense(64, activation='relu')(inputs)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "predictions = layers.Dense(10, activation='softmax')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "AFmspHeG1_W7"
      },
      "cell_type": "markdown",
      "source": [
        "Instantiate the model given inputs and outputs."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5k5uzlyu16HM",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.Model(inputs=inputs, outputs=predictions)\n",
        "\n",
        "# The compile step specifies the training configuration.\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Trains for 5 epochs\n",
        "model.fit(data, labels, batch_size=32, epochs=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "EcKSLH3i0E2k"
      },
      "cell_type": "markdown",
      "source": [
        "### Model subclassing\n",
        "\n",
        "Build a fully-customizable model by subclassing `tf.keras.Model` and defining\n",
        "your own forward pass. Create layers in the `__init__` method and set them as\n",
        "attributes of the class instance. Define the forward pass in the `call` method.\n",
        "\n",
        "Model subclassing is particularly useful when\n",
        "[eager execution](./eager.md) is enabled since the forward pass\n",
        "can be written imperatively.\n",
        "\n",
        "Note: to make sure the forward pass is *always* run imperatively, you must set `dynamic=True` when calling the super constructor.\n",
        "\n",
        "Key Point: Use the right API for the job. While model subclassing offers\n",
        "flexibility, it comes at a cost of greater complexity and more opportunities for\n",
        "user errors. If possible, prefer the functional API.\n",
        "\n",
        "The following example shows a subclassed `tf.keras.Model` using a custom forward\n",
        "pass that does not have to be run imperatively:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KLiHWzcn2Fzk",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, num_classes=10):\n",
        "    super(MyModel, self).__init__(name='my_model')\n",
        "    self.num_classes = num_classes\n",
        "    # Define your layers here.\n",
        "    self.dense_1 = layers.Dense(32, activation='relu')\n",
        "    self.dense_2 = layers.Dense(num_classes, activation='sigmoid')\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # Define your forward pass here,\n",
        "    # using layers you previously defined (in `__init__`).\n",
        "    x = self.dense_1(inputs)\n",
        "    return self.dense_2(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ShDD4fv72KGc"
      },
      "cell_type": "markdown",
      "source": [
        "Instantiate the new model class:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "42C-qQHm0E2l",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = MyModel(num_classes=10)\n",
        "\n",
        "# The compile step specifies the training configuration.\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Trains for 5 epochs.\n",
        "model.fit(data, labels, batch_size=32, epochs=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "yqRQiKj20E2o"
      },
      "cell_type": "markdown",
      "source": [
        "### Custom layers\n",
        "\n",
        "Create a custom layer by subclassing `tf.keras.layers.Layer` and implementing\n",
        "the following methods:\n",
        "\n",
        "* `__init__`: Optionally define sublayers to be used by this layer.\n",
        "* `build`: Create the weights of the layer. Add weights with the `add_weight`\n",
        "  method.\n",
        "* `call`: Define the forward pass.\n",
        "* Optionally, a layer can be serialized by implementing the `get_config` method\n",
        "  and the `from_config` class method.\n",
        "\n",
        "Here's an example of a custom layer that implements a `matmul` of an input with\n",
        "a kernel matrix:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "l7BFnIHr2WNc",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MyLayer(layers.Layer):\n",
        "\n",
        "  def __init__(self, output_dim, **kwargs):\n",
        "    self.output_dim = output_dim\n",
        "    super(MyLayer, self).__init__(**kwargs)\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    # Create a trainable weight variable for this layer.\n",
        "    self.kernel = self.add_weight(name='kernel',\n",
        "                                  shape=(input_shape[1], self.output_dim),\n",
        "                                  initializer='uniform',\n",
        "                                  trainable=True)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs, self.kernel)\n",
        "\n",
        "  def get_config(self):\n",
        "    base_config = super(MyLayer, self).get_config()\n",
        "    base_config['output_dim'] = self.output_dim\n",
        "    return base_config\n",
        "\n",
        "  @classmethod\n",
        "  def from_config(cls, config):\n",
        "    return cls(**config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "8wXDRgXV2ZrF"
      },
      "cell_type": "markdown",
      "source": [
        "Create a model using your custom layer:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "uqH-cY0h0E2p",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    MyLayer(10),\n",
        "    layers.Activation('softmax')])\n",
        "\n",
        "# The compile step specifies the training configuration\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Trains for 5 epochs.\n",
        "model.fit(data, labels, batch_size=32, epochs=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "llipvR5wIl_t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Learn more about creating new layers and models from scratch with subclassing in the [Guide to writing layers and models from scratch in TensorFlow 2.0](./writing_layers_and_models_from_scratch_in_tensorflow_2)."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Lu8cc3AJ0E2v"
      },
      "cell_type": "markdown",
      "source": [
        "## Callbacks\n",
        "\n",
        "A callback is an object passed to a model to customize and extend its behavior\n",
        "during training. You can write your own custom callback, or use the built-in\n",
        "`tf.keras.callbacks` that include:\n",
        "\n",
        "* `tf.keras.callbacks.ModelCheckpoint`: Save checkpoints of your model at\n",
        "  regular intervals.\n",
        "* `tf.keras.callbacks.LearningRateScheduler`: Dynamically change the learning\n",
        "  rate.\n",
        "* `tf.keras.callbacks.EarlyStopping`: Interrupt training when validation\n",
        "  performance has stopped improving.\n",
        "* `tf.keras.callbacks.TensorBoard`: Monitor the model's behavior using\n",
        "  [TensorBoard](./summaries_and_tensorboard.md).\n",
        "\n",
        "To use a `tf.keras.callbacks.Callback`, pass it to the model's `fit` method:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "rdYwzSYV0E2v",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "  # Interrupt training if `val_loss` stops improving for over 2 epochs\n",
        "  tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\n",
        "  # Write TensorBoard logs to `./logs` directory\n",
        "  tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
        "]\n",
        "model.fit(data, labels, batch_size=32, epochs=5, callbacks=callbacks,\n",
        "          validation_data=(val_data, val_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ghhaGfX62abv"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Save and restore"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "qnl7K-aI0E2z"
      },
      "cell_type": "markdown",
      "source": [
        "### Weights only\n",
        "\n",
        "Save and load the weights of a model using `tf.keras.Model.save_weights`:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "uQIANjB94fLB",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "layers.Dense(64, activation='relu', input_shape=(32,)),\n",
        "layers.Dense(10, activation='softmax')])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "4eoHJ-ny0E21",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Save weights to a TensorFlow Checkpoint file\n",
        "model.save_weights('./weights/my_model')\n",
        "\n",
        "# Restore the model's state,\n",
        "# this requires a model with the same architecture.\n",
        "model.load_weights('./weights/my_model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "u25Id3xe0E25"
      },
      "cell_type": "markdown",
      "source": [
        "By default, this saves the model's weights in the\n",
        "[TensorFlow checkpoint](./checkpoints.md) file format. Weights can\n",
        "also be saved to the Keras HDF5 format (the default for the multi-backend\n",
        "implementation of Keras):"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JSAYoFEd0E26",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Save weights to a HDF5 file\n",
        "model.save_weights('my_model.h5', save_format='h5')\n",
        "\n",
        "# Restore the model's state\n",
        "model.load_weights('my_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "mje_yKL10E29"
      },
      "cell_type": "markdown",
      "source": [
        "### Configuration only\n",
        "\n",
        "A model's configuration can be saved—this serializes the model architecture\n",
        "without any weights. A saved configuration can recreate and initialize the same\n",
        "model, even without the code that defined the original model. Keras supports\n",
        "JSON and YAML serialization formats:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "EbET0oJTzGkq",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Serialize a model to JSON format\n",
        "json_string = model.to_json()\n",
        "json_string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pX_badhH3yWV",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pprint\n",
        "pprint.pprint(json.loads(json_string))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Q7CIa05r4yTb"
      },
      "cell_type": "markdown",
      "source": [
        "Recreate the model (newly initialized) from the JSON:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "J9UFv9k00E2_",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fresh_model = tf.keras.models.model_from_json(json_string)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "t5NHtICh4uHK"
      },
      "cell_type": "markdown",
      "source": [
        "Serializing a model to YAML format requires that you install `pyyaml` *before you import TensorFlow*:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aj24KB3Z36S4",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "yaml_string = model.to_yaml()\n",
        "print(yaml_string)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "O53Kerfl43v7"
      },
      "cell_type": "markdown",
      "source": [
        "Recreate the model from the YAML:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "77yRuwg03_MG",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fresh_model = tf.keras.models.model_from_yaml(yaml_string)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "xPvOSSzM0E3B"
      },
      "cell_type": "markdown",
      "source": [
        "Caution: Subclassed models are not serializable because their architecture is\n",
        "defined by the Python code in the body of the `call` method."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "iu8qMwld4-71"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Entire model\n",
        "\n",
        "The entire model can be saved to a file that contains the weight values, the\n",
        "model's configuration, and even the optimizer's configuration. This allows you\n",
        "to checkpoint a model and resume training later—from the exact same\n",
        "state—without access to the original code."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "45oNY34Z0E3C",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a simple model\n",
        "model = tf.keras.Sequential([\n",
        "  layers.Dense(10, activation='softmax', input_shape=(32,)),\n",
        "  layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(data, labels, batch_size=32, epochs=5)\n",
        "\n",
        "\n",
        "# Save entire model to a HDF5 file\n",
        "model.save('my_model.h5')\n",
        "\n",
        "# Recreate the exact same model, including weights and optimizer.\n",
        "model = tf.keras.models.load_model('my_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wGVBURDtI_I6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Learn more about saving and serialization for Keras models in the [Guide to saving and Serializing Models with Keras in TensorFlow 2.0](./saving_and_serializing_models_with_keras_in_tensorflow_2)."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "PMOWhDOB0E3E"
      },
      "cell_type": "markdown",
      "source": [
        "## Eager execution\n",
        "\n",
        "[Eager execution](./eager.md) is an imperative programming\n",
        "environment that evaluates operations immediately. This is not required for\n",
        "Keras, but is supported by `tf.keras` and useful for inspecting your program and\n",
        "debugging.\n",
        "\n",
        "All of the `tf.keras` model-building APIs are compatible with eager execution.\n",
        "And while the `Sequential` and functional APIs can be used, eager execution\n",
        "especially benefits *model subclassing* and building *custom layers*—the APIs\n",
        "that require you to write the forward pass as code (instead of the APIs that\n",
        "create models by assembling existing layers).\n",
        "\n",
        "See the [eager execution guide](./eager.ipynb#build_a_model) for\n",
        "examples of using Keras models with custom training loops and `tf.GradientTape`.\n",
        "You can also find a complete, short example [here](https://github.com/tensorflow/docs/blob/master/site/en/r2/tutorials/quickstart/advanced.ipynb)."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "2wG3NVco5B5V"
      },
      "cell_type": "markdown",
      "source": [
        "## Distribution\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "6PJZ6e9J5JHF"
      },
      "cell_type": "markdown",
      "source": [
        "### Multiple GPUs\n",
        "\n",
        "`tf.keras` models can run on multiple GPUs using\n",
        "`tf.distribute.Strategy`. This API provides distributed\n",
        "training on multiple GPUs with almost no changes to existing code.\n",
        "\n",
        "Currently, `tf.distribute.MirroredStrategy` is the only supported\n",
        "distribution strategy. `MirroredStrategy` does in-graph replication with\n",
        "synchronous training using all-reduce on a single machine. To use\n",
        "`distribute.Strategy`s with Keras, nest the optimizer instantiation and model construction and compilation in a `Strategy`'s `.scope()`, then\n",
        "train the model.\n",
        "\n",
        "The following example distributes a `tf.keras.Model` across multiple GPUs on a\n",
        "single machine.\n",
        "\n",
        "First, define a model inside the distributed strategy scope:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "sbaRr7g-0E3I",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "with strategy.scope():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.Dense(16, activation='relu', input_shape=(10,)))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "  optimizer = tf.keras.optimizers.SGD(0.2)\n",
        "\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "rO9MiL6X0E3O"
      },
      "cell_type": "markdown",
      "source": [
        "Next, train the model on data as usual:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "BEwFq4PM0E3P",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "  x = np.random.random((1024, 10))\n",
        "  y = np.random.randint(2, size=(1024, 1))\n",
        "  x = tf.cast(x, tf.float32)\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "  dataset = dataset.shuffle(buffer_size=1024).batch(32)\n",
        "\n",
        "  model.fit(dataset, epochs=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "N6BXU5F90E3U"
      },
      "cell_type": "markdown",
      "source": [
        "For more information, see the [full guide on Distributed Training in TensorFlow](distribute_strategy.ipynb)."
      ]
    }
  ]
}