{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MhoQ0WE77laV"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "both",
        "colab": {},
        "colab_type": "code",
        "id": "_ckMIh7O7s6D"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jYysdyb-CaWM"
      },
      "source": [
        "# Distribution Strategy with Training Loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S5Uhzt6vVIB2"
      },
      "source": [
        "\u003ctable class=\"tfo-notebook-buttons\" align=\"left\"\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://www.tensorflow.org/alpha/tutorials/distribute/training_loops\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" /\u003eView on TensorFlow.org\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/r2/tutorials/distribute/training_loops.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /\u003eRun in Google Colab\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/r2/tutorials/distribute/training_loops.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /\u003eView source on GitHub\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "\u003c/table\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FbVhjPpzn6BM"
      },
      "source": [
        "This tutorial demonstrates how to use [tf.distribute.Strategy](https://www.tensorflow.org/guide/distribute_strategy) with custom training loops. We will train a simple CNN model on the fashion MNIST dataset. The fashion MNIST dataset contains 60000 train images of size 28 x 28 and 10000 test images of size 28 x 28.\n",
        "\n",
        "We are using custom training loops to train our model because they give us flexibility and a greater control on training. Moreover, it is easier to debug the model and the training loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "dzLKpmZICaWN"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "# Import TensorFlow\n",
        "!pip install tf-nightly-gpu-2.0-preview\n",
        "import tensorflow as tf\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MM6W__qraV55"
      },
      "source": [
        "## Download the fashion mnist dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "7MqDQO0KCaWS"
      },
      "outputs": [],
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Adding a dimension to the array -\u003e new shape == (28, 28, 1)\n",
        "# We are doing this because the first layer in our model is a convolutional \n",
        "# layer and it requires a 4D input (batch_size, height, width, channels).\n",
        "# batch_size dimension will be added later on.\n",
        "train_images = train_images[..., None]\n",
        "test_images = test_images[..., None]\n",
        "\n",
        "# Getting the images in [0, 1] range.\n",
        "train_images = train_images / np.float32(255)\n",
        "test_images = test_images / np.float32(255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4AXoHhrsbdF3"
      },
      "source": [
        "## Create a strategy to distribute the variables and the graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5mVuLZhbem8d"
      },
      "source": [
        "How does `tf.distribute.MirroredStrategy` strategy work?\n",
        "\n",
        "*   All the variables and the model graph is replicated on the replicas.\n",
        "*   Input is evenly distributed across the replicas.\n",
        "*   Each replica calculates the loss and gradients for the input it received.\n",
        "*   The gradients are synced across all the replicas by summing them. \n",
        "*   After the sync, the same update is made to the copies of the variables on each replica.\n",
        "\n",
        "Note: You can put all the code below inside a single scope. We are dividing it into several code cells for illustration purposes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "F2VeZUWUj5S4"
      },
      "outputs": [],
      "source": [
        "# If the list of devices is not specified in the \n",
        "# `tf.distribute.MirroredStrategy` constructor, it will be auto-detected.\n",
        "strategy = tf.distribute.MirroredStrategy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ZngeM_2o0_JO"
      },
      "outputs": [],
      "source": [
        "print ('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "k53F5I_IiGyI"
      },
      "source": [
        "## Setup input pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0Qb6nDgxiN_n"
      },
      "source": [
        "If a model is trained on multiple GPUs, the batch size should be increased accordingly so as to make effective use of the extra computing power. Moreover, the learning rate should be tuned accordingly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "jwJtsCQhHK-E"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = len(train_images)\n",
        "\n",
        "BATCH_SIZE_PER_REPLICA = 64\n",
        "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
        "\n",
        "EPOCHS = 10\n",
        "train_steps_per_epoch = len(train_images) // BATCH_SIZE\n",
        "test_steps_per_epoch = len(test_images) // BATCH_SIZE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J7fj3GskHC8g"
      },
      "source": [
        "`strategy.experimental_make_numpy_iterator` creates an iterator that evenly distributes the data across all the replicas.\n",
        "\n",
        "\n",
        "This is more efficient than using `tf.data.Dataset.from_tensor_slices` directly since it avoids recording the training data as a constant in the graph. \n",
        "\n",
        "```python\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "  (train_images, train_labels)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "train_iterator = strategy.make_dataset_iterator(train_dataset)\n",
        "```\n",
        "\n",
        "Note: This API is expected to change in the near future."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "WYrMNNDhAvVl"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  train_iterator = strategy.experimental_make_numpy_iterator(\n",
        "      (train_images, train_labels), BATCH_SIZE, shuffle=BUFFER_SIZE)\n",
        "\n",
        "  test_iterator = strategy.experimental_make_numpy_iterator(\n",
        "      (test_images, test_labels), BATCH_SIZE, shuffle=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bAXAo_wWbWSb"
      },
      "source": [
        "## Model Creation\n",
        "\n",
        "Create a model using `tf.keras.Sequential`. You can also use the Model Subclassing API to do this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "9ODch-OFCaW4"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(),\n",
        "      tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\n",
        "      tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "9iagoTBfijUz"
      },
      "outputs": [],
      "source": [
        "# Create a checkpoint directory to store the checkpoints.\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e-wlFFZbP33n"
      },
      "source": [
        "## Define the loss function\n",
        "\n",
        "Normally, on a single machine with 1 GPU/CPU, loss is divided by the number of examples in the batch of input.\n",
        "\n",
        "*So, how is the loss calculated in distribution strategies?*\n",
        "\n",
        "\u003e For an example, let's say you have 4 GPU's and a batch size of 64. One batch of input is distributed \n",
        "across the replicas (4 GPU's), each replica getting an input of size 16. \n",
        "\n",
        "\u003e The model on each replica does a forward pass with its respective input and calculates the loss. Now, instead of dividing the loss by the number of examples in its respective input (16), the loss is divided by the global input size (64).\n",
        "\n",
        "*Why is this done?*\n",
        "\n",
        "\u003e This is done because after the gradients are calculated on each replica, they are synced across the replicas by **summing** them.\n",
        "\n",
        "*How to handle this in TensorFlow?*\n",
        "\n",
        "\u003e `tf.keras.losses` handles this automatically. \n",
        "\n",
        "\u003e If you distribute a custom loss function, don't implement it using `tf.reduce_mean` (which divides by the local batch size), divide the sum by the global batch size:\n",
        "\n",
        "```python\n",
        "scale_loss = tf.reduce_sum(loss) * (1. / global_batch_size)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "R144Wci782ix"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "w8y54-o9T2Ni"
      },
      "source": [
        "## Define the metrics to track loss and accuracy\n",
        "\n",
        "These metrics track the loss and the accuracy. You can use `.result()` to get the accumulated statistics at any time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "zt3AHb46Tr3w"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "  test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "\n",
        "  train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "      name='train_accuracy')\n",
        "  test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "      name='test_accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iuKuNXPORfqJ"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "OrMmakq5EqeQ"
      },
      "outputs": [],
      "source": [
        "# model and optimizer must be created under `strategy.scope`.\n",
        "with strategy.scope():\n",
        "  model = create_model()\n",
        "\n",
        "  optimizer = tf.keras.optimizers.Adam()\n",
        "  \n",
        "  checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ez1WaKUyse5w"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  # Train step\n",
        "  def train_step(inputs):\n",
        "    images, labels = inputs\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions = model(images, training=True)\n",
        "      loss = loss_object(labels, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(labels, predictions)\n",
        "\n",
        "  # Test step\n",
        "  def test_step(inputs):\n",
        "    images, labels = inputs\n",
        "\n",
        "    predictions = model(images, training=False)\n",
        "    t_loss = loss_object(labels, predictions)\n",
        "\n",
        "    test_loss(t_loss)\n",
        "    test_accuracy(labels, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "gX975dMSNw0e"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  # `experimental_run` replicates the provided computation and runs it \n",
        "  # with the distributed input.\n",
        "  \n",
        "  @tf.function\n",
        "  def distributed_train():\n",
        "    return strategy.experimental_run(train_step, train_iterator)\n",
        "  \n",
        "  @tf.function\n",
        "  def distributed_test():\n",
        "    return strategy.experimental_run(test_step, test_iterator)\n",
        "    \n",
        "  for epoch in range(EPOCHS):\n",
        "    # Note: This code is expected to change in the near future.\n",
        "    \n",
        "    # TRAIN LOOP\n",
        "    # Initialize the iterator\n",
        "    train_iterator.initialize()\n",
        "    for _ in range(train_steps_per_epoch):\n",
        "      distributed_train()\n",
        "\n",
        "    # TEST LOOP\n",
        "    test_iterator.initialize()\n",
        "    for _ in range(test_steps_per_epoch):\n",
        "      distributed_test()\n",
        "    \n",
        "    if epoch % 2 == 0:\n",
        "      checkpoint.save(checkpoint_prefix)\n",
        "\n",
        "    template = (\"Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, \"\n",
        "                \"Test Accuracy: {}\")\n",
        "    print (template.format(epoch+1, train_loss.result(), \n",
        "                           train_accuracy.result()*100, test_loss.result(), \n",
        "                           test_accuracy.result()*100))\n",
        "    \n",
        "    train_loss.reset_states()\n",
        "    test_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    test_accuracy.reset_states()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-q5qp31IQD8t"
      },
      "source": [
        "## Restore the latest checkpoint and test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WNW2P00bkMGJ"
      },
      "source": [
        "A model checkpointed with distribution strategy can be restored with and without distribution strategy. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "pg3B-Cw_cn3a"
      },
      "outputs": [],
      "source": [
        "eval_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "      name='eval_accuracy')\n",
        "\n",
        "new_model = create_model()\n",
        "new_optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "7qYii7KUYiSM"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def eval_step(images, labels):\n",
        "  predictions = new_model(images, training=False)\n",
        "  eval_accuracy(labels, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "LeZ6eeWRoUNq"
      },
      "outputs": [],
      "source": [
        "checkpoint = tf.train.Checkpoint(optimizer=new_optimizer, model=new_model)\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "for images, labels in test_dataset:\n",
        "  eval_step(images, labels)\n",
        "\n",
        "print ('Accuracy after restoring the saved model without strategy: {}'.format(\n",
        "    eval_accuracy.result()*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6hEJNsokjOKs"
      },
      "source": [
        "## Next Steps\n",
        "\n",
        "Try out the new Distribution Strategy API on your models."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "//learning/brain/python/client:tpu_hw_notebook",
        "kind": "private"
      },
      "name": "training_loops.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
