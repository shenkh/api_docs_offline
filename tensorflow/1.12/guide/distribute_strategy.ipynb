{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "# Distributed Training in TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r6P32iYYV27b"
      },
      "source": [
        "\u003ctable class=\"tfo-notebook-buttons\" align=\"left\"\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://www.tensorflow.org/guide/distribute_strategy.\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" /\u003eView on TensorFlow.org\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/distribute_strategy.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /\u003eRun in Google Colab\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/distribute_strategy.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /\u003eView source on GitHub\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "\u003c/table\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xHxb-dlhMIzW"
      },
      "source": [
        "## Overview\n",
        "\n",
        "The `tf.distribute.Strategy` API is an easy way to distribute your training\n",
        "across multiple devices/machines. Our goal is to allow users to use existing\n",
        "models and training code with minimal changes to enable distributed training.\n",
        "\n",
        "Currently, in core TensorFlow, we support `tf.distribute.MirroredStrategy`. This\n",
        "does in-graph replication with synchronous training on many GPUs on one machine.\n",
        "Essentially, we create copies of all variables in the model's layers on each\n",
        "device. We then use all-reduce to combine gradients across the devices before\n",
        "applying them to the variables to keep them in sync.\n",
        "\n",
        "Many other strategies are available in TensorFlow 1.12+ contrib and will soon be\n",
        "available in core TensorFlow. You can find more information about them in the\n",
        "contrib\n",
        "[README](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/distribute).\n",
        "You can also read the\n",
        "[public design review](https://github.com/tensorflow/community/blob/master/rfcs/20181016-replicator.md)\n",
        "for updating the `tf.distribute.Strategy` API as part of the move from contrib\n",
        "to core TF.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MUXex9ctTuDB"
      },
      "source": [
        "## Example with Keras API\n",
        "\n",
        "Let's see how to scale to multiple GPUs on one machine using `MirroredStrategy`\n",
        "with [tf.keras](https://www.tensorflow.org/guide/keras).\n",
        "\n",
        "We will take a very simple model consisting of a single layer. First, we will import Tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "0qV0W-EgUd2W"
      },
      "outputs": [],
      "source": [
        "!pip install tf-nightly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "74rHkS_DB3X2"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TlH8vx6BB3X9"
      },
      "source": [
        "To distribute a Keras model on multiple GPUs using `MirroredStrategy`, we first instantiate a `MirroredStrategy` object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "4j0tdf4YB3X9"
      },
      "outputs": [],
      "source": [
        "strategy = tf.distribute.MirroredStrategy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1BnQYQTpB3YA"
      },
      "source": [
        "We then create and compile the Keras model in `strategy.scope`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "IexhL_vIB3YA"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  inputs = tf.keras.layers.Input(shape=(1,))\n",
        "  predictions = tf.keras.layers.Dense(1)(inputs)\n",
        "  model = tf.keras.models.Model(inputs=inputs, outputs=predictions)\n",
        "  model.compile(loss='mse',\n",
        "                optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OtnnUwvmB3X5"
      },
      "source": [
        "Let's also define a simple input dataset for training this model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "iXMJ3G9NB3X6"
      },
      "outputs": [],
      "source": [
        "train_dataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(10000).batch(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6EophnOAB3YD"
      },
      "source": [
        "To train the model we call Keras `fit` API using the input dataset that we\n",
        "created earlier, same as how we would in a non-distributed case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "7MVw_6CqB3YD"
      },
      "outputs": [],
      "source": [
        "model.fit(train_dataset, epochs=5, steps_per_epoch=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y0AQKNTaB3YG"
      },
      "source": [
        "Similarly, we can also call `evaluate` and `predict` as before using appropriate\n",
        "datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "lmXh3pGaB3YH"
      },
      "outputs": [],
      "source": [
        "eval_dataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(100).batch(10)\n",
        "model.evaluate(eval_dataset, steps=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "vVzt5vbiKL_r"
      },
      "outputs": [],
      "source": [
        "predict_dataset = tf.data.Dataset.from_tensors(([1.])).repeat(10).batch(2)\n",
        "model.predict(predict_dataset, steps=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OtIGjUImB3YK"
      },
      "source": [
        "That's all you need to train your model with Keras on multiple GPUs with\n",
        "`MirroredStrategy`. It will take care of splitting up\n",
        "the input dataset, replicating layers and variables on each device, and\n",
        "combining and applying gradients.\n",
        "\n",
        "The model and input code does not have to change because we have changed the\n",
        "underlying components of TensorFlow (such as optimizer, batch norm and\n",
        "summaries) to become strategy-aware. That means those components know how to\n",
        "combine their state across devices. Further, saving and checkpointing works\n",
        "seamlessly, so you can save with one or no distribute strategy and resume with\n",
        "another."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BlCocFJnaLuY"
      },
      "source": [
        "## Example with Estimator API\n",
        "\n",
        "You can also use `tf.distribute.Strategy` API with\n",
        "[`Estimator`](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator).\n",
        "Let's see a simple example of it's usage with `MirroredStrategy`.\n",
        "\n",
        "We will use the `LinearRegressor` premade estimator as an example. To use `MirroredStrategy` with Estimator, all we need to do is:\n",
        "\n",
        "* Create an instance of the `MirroredStrategy` class.\n",
        "* Pass it to the\n",
        "[`RunConfig`](https://www.tensorflow.org/api_docs/python/tf/estimator/RunConfig)\n",
        "parameter of the custom or premade `Estimator`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "oGFY5nW_B3YU"
      },
      "outputs": [],
      "source": [
        "strategy = tf.distribute.MirroredStrategy()\n",
        "config = tf.estimator.RunConfig(\n",
        "    train_distribute=strategy, eval_distribute=strategy)\n",
        "regressor = tf.estimator.LinearRegressor(\n",
        "    feature_columns=[tf.feature_column.numeric_column('feats')],\n",
        "    optimizer='SGD',\n",
        "    config=config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KyCrUWsOB3YO"
      },
      "source": [
        "We will define a simple input function to feed data for training this model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2ky2ve2PB3YP"
      },
      "outputs": [],
      "source": [
        "def input_fn():\n",
        "  return tf.data.Dataset.from_tensors(({\"feats\":[1.]}, [1.])).repeat(10000).batch(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZVNXFlkkPfmR"
      },
      "source": [
        "Then we can call `train` on the regressor instance to train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "nhJtp3HzOpSl"
      },
      "outputs": [],
      "source": [
        "regressor.train(input_fn=input_fn, steps=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dlBf7pVKPpp1"
      },
      "source": [
        "And we can `evaluate` to evaluate the trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Si0m3njTOro-"
      },
      "outputs": [],
      "source": [
        "regressor.evaluate(input_fn=input_fn, steps=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nPJue-5CB3YV"
      },
      "source": [
        "That's it! This change will now configure estimator to run on all GPUs on your\n",
        "machine.\n",
        "\n",
        "\n",
        "## Customization and Performance Tips\n",
        "\n",
        "Above, we showed the easiest way to use `MirroredStrategy`. There are few things\n",
        "you can customize in practice:\n",
        "\n",
        "*   You can specify a list of specific GPUs (using param `devices`), in case you\n",
        "    don't want auto detection.\n",
        "*   You can specify various parameters for all reduce with the\n",
        "    `cross_device_ops` param, such as the all reduce algorithm to use, and\n",
        "    gradient repacking.\n",
        "\n",
        "We've tried to make it such that you get the best performance for your existing\n",
        "model without having to specify any additional options. We also recommend you\n",
        "follow the tips from\n",
        "[Input Pipeline Performance Guide](https://www.tensorflow.org/performance/datasets_performance).\n",
        "Specifically, we found using\n",
        "[`map_and_batch`](https://www.tensorflow.org/performance/datasets_performance#map_and_batch)\n",
        "and\n",
        "[`dataset.prefetch`](https://www.tensorflow.org/performance/datasets_performance#pipelining)\n",
        "in the input function gives a solid boost in performance. When using\n",
        "`dataset.prefetch`, use `buffer_size=tf.data.experimental.AUTOTUNE` to let it detect optimal buffer size.\n",
        "\n",
        "## Caveats\n",
        "\n",
        "This API is still in progress there are a lot of improvements forthcoming:\n",
        "\n",
        "*   Summaries are only computed in the first replica in `MirroredStrategy`.\n",
        "*   PartitionedVariables are not supported yet.\n",
        "*   Performance improvements, especially w.r.t. input handling, eager execution\n",
        "    etc.\n",
        "\n",
        "## What's next?\n",
        "\n",
        "`tf.distribute.Strategy` is actively under development and we will be adding more examples and tutorials in the near future. Please give it a try, we welcome your feedback via [issues on GitHub](https://github.com/tensorflow/tensorflow/issues/new)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "last_runtime": {
        "build_target": "//learning/brain/python/client:colab_notebook",
        "kind": "private"
      },
      "name": "distribute_strategy.ipynb",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "129wLqbRhI-xYhwnGrEwJLfc6vDP5NVB-",
          "timestamp": 1545117257785
        }
      ],
      "toc_visible": true,
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
