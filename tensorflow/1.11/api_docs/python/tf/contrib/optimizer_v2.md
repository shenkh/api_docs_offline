<div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.contrib.optimizer_v2" />
<meta itemprop="path" content="Stable" />
</div>

# Module: tf.contrib.optimizer_v2



Defined in [`tensorflow/contrib/optimizer_v2/optimizer_v2_symbols.py`](https://www.tensorflow.org/code/tensorflow/contrib/optimizer_v2/optimizer_v2_symbols.py).

Distribution-aware version of Optimizer.

## Classes

[`class AdadeltaOptimizer`](../../tf/contrib/optimizer_v2/AdadeltaOptimizer.md): Optimizer that implements the Adadelta algorithm.

[`class AdagradOptimizer`](../../tf/contrib/optimizer_v2/AdagradOptimizer.md): Optimizer that implements the Adagrad algorithm.

[`class AdamOptimizer`](../../tf/contrib/optimizer_v2/AdamOptimizer.md): Optimizer that implements the Adam algorithm.

[`class GradientDescentOptimizer`](../../tf/contrib/optimizer_v2/GradientDescentOptimizer.md): Optimizer that implements the gradient descent algorithm.

[`class MomentumOptimizer`](../../tf/contrib/optimizer_v2/MomentumOptimizer.md): Optimizer that implements the Momentum algorithm.

[`class OptimizerV2`](../../tf/contrib/optimizer_v2/OptimizerV2.md): Updated base class for optimizers.

[`class RMSPropOptimizer`](../../tf/contrib/optimizer_v2/RMSPropOptimizer.md): Optimizer that implements the RMSProp algorithm.

