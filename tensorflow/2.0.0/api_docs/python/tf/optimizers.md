<div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.optimizers" />
<meta itemprop="path" content="Stable" />
</div>

# Module: tf.optimizers

### Aliases:

* Module `tf.keras.optimizers`
* Module `tf.optimizers`



Defined in [`tensorflow/python/keras/api/_v2/keras/optimizers/__init__.py`](/code/stable/tensorflow/python/keras/api/_v2/keras/optimizers/__init__.py).

Built-in optimizer classes.

## Modules

[`schedules`](../tf/optimizers/schedules.md) module: Public API for tf.keras.optimizers.schedules namespace.

## Classes

[`class Adadelta`](../tf/optimizers/Adadelta.md): Optimizer that implements the Adadelta algorithm.

[`class Adagrad`](../tf/optimizers/Adagrad.md): Optimizer that implements the Adagrad algorithm.

[`class Adam`](../tf/optimizers/Adam.md): Optimizer that implements the Adam algorithm.

[`class Adamax`](../tf/optimizers/Adamax.md): Optimizer that implements the Adamax algorithm.

[`class Ftrl`](../tf/optimizers/Ftrl.md): Optimizer that implements the FTRL algorithm.

[`class Nadam`](../tf/optimizers/Nadam.md): Optimizer that implements the NAdam algorithm.

[`class Optimizer`](../tf/optimizers/Optimizer.md): Updated base class for optimizers.

[`class RMSprop`](../tf/optimizers/RMSprop.md): Optimizer that implements the RMSprop algorithm.

[`class SGD`](../tf/optimizers/SGD.md): Stochastic gradient descent and momentum optimizer.

## Functions

[`deserialize(...)`](../tf/optimizers/deserialize.md): Inverse of the `serialize` function.

[`get(...)`](../tf/optimizers/get.md): Retrieves a Keras Optimizer instance.

[`serialize(...)`](../tf/optimizers/serialize.md)

