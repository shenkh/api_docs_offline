
<!DOCTYPE html>

<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"> <!--<![endif]-->
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Loading a PyTorch Model in C++ — PyTorch Tutorials 1.0.0 documentation</title>
<link href="../_static/css/theme.css" rel="stylesheet" type="text/css"/>
<!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
<link href="../_static/gallery.css" rel="stylesheet" type="text/css"/>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="cpp_frontend.html" rel="next" title="Using the PyTorch C++ Frontend"/>
<link href="ONNXLive.html" rel="prev" title="ONNX Live Tutorial"/>
<script src="../_static/js/modernizr.min.js"></script>
</head>
<div class="container-fluid header-holder tutorials-header" id="header-holder">
<div class="container">
<div class="header-container">
<a aria-label="PyTorch" class="header-logo" href="https://pytorch.org/"></a>
<div class="main-menu">
<ul>
<li>
<a href="https://pytorch.org/get-started">Get Started</a>
</li>
<li>
<a href="https://pytorch.org/features">Features</a>
</li>
<li>
<a href="https://pytorch.org/ecosystem">Ecosystem</a>
</li>
<li>
<a href="https://pytorch.org/blog/">Blog</a>
</li>
<li class="active">
<a href="https://pytorch.org/tutorials">Tutorials</a>
</li>
<li>
<a href="https://pytorch.org/docs/stable/index.html">Docs</a>
</li>
<li>
<a href="https://pytorch.org/resources">Resources</a>
</li>
<li>
<a href="https://github.com/pytorch/pytorch">Github</a>
</li>
</ul>
</div>
<a class="main-menu-open-button" data-behavior="open-mobile-menu" href="#"></a>
</div>
</div>
</div>
<body class="pytorch-body">
<div class="table-of-contents-link-wrapper">
<span>Table of Contents</span>
<a class="toggle-table-of-contents" data-behavior="toggle-table-of-contents" href="#"></a>
</div>
<nav class="pytorch-left-menu" data-toggle="wy-nav-shift" id="pytorch-left-menu">
<div class="pytorch-side-scroll">
<div aria-label="main navigation" class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation">
<div class="pytorch-left-menu-search">
<div class="version">
                  1.0.0
                </div>
<div role="search">
<form action="../search.html" class="wy-form" id="rtd-search-form" method="get">
<input name="q" placeholder="Search Tutorials" type="text"/>
<input name="check_keywords" type="hidden" value="yes"/>
<input name="area" type="hidden" value="default"/>
</form>
</div>
</div>
<p class="caption"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/deep_learning_60min_blitz.html">Deep Learning with PyTorch: A 60 Minute Blitz</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/data_loading_tutorial.html">Data Loading and Processing Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/pytorch_with_examples.html">Learning PyTorch with Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/transfer_learning_tutorial.html">Transfer Learning Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/deploy_seq2seq_hybrid_frontend_tutorial.html">Deploying a Seq2Seq Model with the Hybrid Frontend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/saving_loading_models.html">Saving and Loading Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/nn_tutorial.html">What is <cite>torch.nn</cite> <em>really</em>?</a></li>
</ul>
<p class="caption"><span class="caption-text">Image</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/torchvision_tutorial.html">TorchVision 0.3 Object Detection Finetuning Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/finetuning_torchvision_models_tutorial.html">Finetuning Torchvision Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/spatial_transformer_tutorial.html">Spatial Transformer Networks Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="neural_style_tutorial.html">Neural Transfer Using PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/fgsm_tutorial.html">Adversarial Example Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="super_resolution_with_caffe2.html">Transfering a Model from PyTorch to Caffe2 and Mobile using ONNX</a></li>
</ul>
<p class="caption"><span class="caption-text">Text</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/chatbot_tutorial.html">Chatbot Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html">Generating Names with a Character-Level RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html">Classifying Names with a Character-Level RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/deep_learning_nlp_tutorial.html">Deep Learning for NLP with Pytorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html">Translation with a Sequence to Sequence Network and Attention</a></li>
</ul>
<p class="caption"><span class="caption-text">Generative</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/dcgan_faces_tutorial.html">DCGAN Tutorial</a></li>
</ul>
<p class="caption"><span class="caption-text">Reinforcement Learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html">Reinforcement Learning (DQN) Tutorial</a></li>
</ul>
<p class="caption"><span class="caption-text">Extending PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="numpy_extensions_tutorial.html">Creating Extensions Using numpy and scipy</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpp_extension.html">Custom C++ and CUDA Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_script_custom_ops.html">Extending TorchScript with Custom C++ Operators</a></li>
</ul>
<p class="caption"><span class="caption-text">Production Usage</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../intermediate/model_parallel_tutorial.html">Model Parallel Best Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/ddp_tutorial.html">Getting Started with Distributed Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dist_tuto.html">Writing Distributed Applications with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/aws_distributed_training_tutorial.html">PyTorch 1.0 Distributed Trainer with Amazon AWS</a></li>
<li class="toctree-l1"><a class="reference internal" href="ONNXLive.html">ONNX Live Tutorial</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Loading a PyTorch Model in C++</a></li>
</ul>
<p class="caption"><span class="caption-text">PyTorch in Other Languages</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cpp_frontend.html">Using the PyTorch C++ Frontend</a></li>
</ul>
</div>
</div>
</nav>
<div class="pytorch-container">
<div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
<div class="pytorch-breadcrumbs-wrapper">
<div aria-label="breadcrumbs navigation" role="navigation">
<ul class="pytorch-breadcrumbs">
<li>
<a href="../index.html">
          
            Tutorials
          
        </a> &gt;
      </li>
<li>Loading a PyTorch Model in C++</li>
<li class="pytorch-breadcrumbs-aside">
<a href="../_sources/advanced/cpp_export.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"/></a>
</li>
</ul>
</div>
</div>
<div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
</div>
<section class="pytorch-content-wrap" data-toggle="wy-nav-shift" id="pytorch-content-wrap">
<div class="pytorch-content-left">
<div class="rst-content">
<div class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
<article class="pytorch-article" id="pytorch-article" itemprop="articleBody">
<div class="section" id="loading-a-pytorch-model-in-c">
<h1>Loading a PyTorch Model in C++<a class="headerlink" href="#loading-a-pytorch-model-in-c" title="Permalink to this headline">¶</a></h1>
<p>As its name suggests, the primary interface to PyTorch is the Python
programming language. While Python is a suitable and preferred language for
many scenarios requiring dynamism and ease of iteration, there are equally many
situations where precisely these properties of Python are unfavorable. One
environment in which the latter often applies is <em>production</em> – the land of
low latencies and strict deployment requirements. For production scenarios, C++
is very often the language of choice, even if only to bind it into another
language like Java, Rust or Go. The following paragraphs will outline the path
PyTorch provides to go from an existing Python model to a serialized
representation that can be <em>loaded</em> and <em>executed</em> purely from C++, with no
dependency on Python.</p>
<div class="section" id="step-1-converting-your-pytorch-model-to-torch-script">
<h2>Step 1: Converting Your PyTorch Model to Torch Script<a class="headerlink" href="#step-1-converting-your-pytorch-model-to-torch-script" title="Permalink to this headline">¶</a></h2>
<p>A PyTorch model’s journey from Python to C++ is enabled by <a class="reference external" href="https://pytorch.org/docs/master/jit.html">Torch Script</a>, a representation of a PyTorch
model that can be understood, compiled and serialized by the Torch Script
compiler. If you are starting out from an existing PyTorch model written in the
vanilla “eager” API, you must first convert your model to Torch Script. In the
most common cases, discussed below, this requires only little effort. If you
already have a Torch Script module, you can skip to the next section of this
tutorial.</p>
<p>There exist two ways of converting a PyTorch model to Torch Script. The first
is known as <em>tracing</em>, a mechanism in which the structure of the model is
captured by evaluating it once using example inputs, and recording the flow of
those inputs through the model. This is suitable for models that make limited
use of control flow. The second approach is to add explicit annotations to your
model that inform the Torch Script compiler that it may directly parse and
compile your model code, subject to the constraints imposed by the Torch Script
language.</p>
<div class="admonition tip">
<p class="first admonition-title">Tip</p>
<p class="last">You can find the complete documentation for both of these methods, as well as
further guidance on which to use, in the official <a class="reference external" href="https://pytorch.org/docs/master/jit.html">Torch Script
reference</a>.</p>
</div>
<div class="section" id="converting-to-torch-script-via-tracing">
<h3>Converting to Torch Script via Tracing<a class="headerlink" href="#converting-to-torch-script-via-tracing" title="Permalink to this headline">¶</a></h3>
<p>To convert a PyTorch model to Torch Script via tracing, you must pass an
instance of your model along with an example input to the <code class="docutils literal notranslate"><span class="pre">torch.jit.trace</span></code>
function. This will produce a <code class="docutils literal notranslate"><span class="pre">torch.jit.ScriptModule</span></code> object with the trace
of your model evaluation embedded in the module’s <code class="docutils literal notranslate"><span class="pre">forward</span></code> method:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchvision</span>

<span class="c1"># An instance of your model.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">()</span>

<span class="c1"># An example input you would normally provide to your model's forward() method.</span>
<span class="n">example</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>

<span class="c1"># Use torch.jit.trace to generate a torch.jit.ScriptModule via tracing.</span>
<span class="n">traced_script_module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">example</span><span class="p">)</span>
</pre></div>
</div>
<p>The traced <code class="docutils literal notranslate"><span class="pre">ScriptModule</span></code> can now be evaluated identically to a regular
PyTorch module:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">In</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="n">output</span> <span class="o">=</span> <span class="n">traced_script_module</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span>
<span class="n">In</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span> <span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:</span><span class="mi">5</span><span class="p">]</span>
<span class="n">Out</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span> <span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.2698</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0381</span><span class="p">,</span>  <span class="mf">0.4023</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3010</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0448</span><span class="p">],</span> <span class="n">grad_fn</span><span class="o">=&lt;</span><span class="n">SliceBackward</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="converting-to-torch-script-via-annotation">
<h3>Converting to Torch Script via Annotation<a class="headerlink" href="#converting-to-torch-script-via-annotation" title="Permalink to this headline">¶</a></h3>
<p>Under certain circumstances, such as if your model employs particular forms of
control flow, you may want to write your model in Torch Script directly and
annotate your model accordingly. For example, say you have the following
vanilla Pytorch model:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="k">class</span> <span class="nc">MyModule</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MyModule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">input</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
          <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">mv</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">+</span> <span class="nb">input</span>
        <span class="k">return</span> <span class="n">output</span>
</pre></div>
</div>
<p>Because the <code class="docutils literal notranslate"><span class="pre">forward</span></code> method of this module uses control flow that is
dependent on the input, it is not suitable for tracing. Instead, we can convert
it to a <code class="docutils literal notranslate"><span class="pre">ScriptModule</span></code> by subclassing it from <code class="docutils literal notranslate"><span class="pre">torch.jit.ScriptModule</span></code> and
adding a <code class="docutils literal notranslate"><span class="pre">@torch.jit.script_method</span></code> annotation to the model’s <code class="docutils literal notranslate"><span class="pre">forward</span></code>
method:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="k">class</span> <span class="nc">MyModule</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">ScriptModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MyModule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">))</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">script_method</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">bool</span><span class="p">(</span><span class="nb">input</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">):</span>
          <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">mv</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">+</span> <span class="nb">input</span>
        <span class="k">return</span> <span class="n">output</span>

<span class="n">my_script_module</span> <span class="o">=</span> <span class="n">MyModule</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
<p>Creating a new <code class="docutils literal notranslate"><span class="pre">MyModule</span></code> object now directly produces an instance of
<code class="docutils literal notranslate"><span class="pre">ScriptModule</span></code> that is ready for serialization.</p>
</div>
</div>
<div class="section" id="step-2-serializing-your-script-module-to-a-file">
<h2>Step 2: Serializing Your Script Module to a File<a class="headerlink" href="#step-2-serializing-your-script-module-to-a-file" title="Permalink to this headline">¶</a></h2>
<p>Once you have a <code class="docutils literal notranslate"><span class="pre">ScriptModule</span></code> in your hands, either from tracing or
annotating a PyTorch model, you are ready to serialize it to a file. Later on,
you’ll be able to load the module from this file in C++ and execute it without
any dependency on Python. Say we want to serialize the <code class="docutils literal notranslate"><span class="pre">ResNet18</span></code> model shown
earlier in the tracing example. To perform this serialization, simply call
<a class="reference external" href="https://pytorch.org/docs/master/jit.html#torch.jit.ScriptModule.save">save</a>
on the module and pass it a filename:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">traced_script_module</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">"model.pt"</span><span class="p">)</span>
</pre></div>
</div>
<p>This will produce a <code class="docutils literal notranslate"><span class="pre">model.pt</span></code> file in your working directory. We have now
officially left the realm of Python and are ready to cross over to the sphere
of C++.</p>
</div>
<div class="section" id="step-3-loading-your-script-module-in-c">
<h2>Step 3: Loading Your Script Module in C++<a class="headerlink" href="#step-3-loading-your-script-module-in-c" title="Permalink to this headline">¶</a></h2>
<p>To load your serialized PyTorch model in C++, your application must depend on
the PyTorch C++ API – also known as <em>LibTorch</em>. The LibTorch distribution
encompasses a collection of shared libraries, header files and CMake build
configuration files. While CMake is not a requirement for depending on
LibTorch, it is the recommended approach and will be well supported into the
future. For this tutorial, we will be building a minimal C++ application using
CMake and LibTorch that simply loads and executes a serialized PyTorch model.</p>
<div class="section" id="a-minimal-c-application">
<h3>A Minimal C++ Application<a class="headerlink" href="#a-minimal-c-application" title="Permalink to this headline">¶</a></h3>
<p>Let’s begin by discussing the code to load a module. The following will already
do:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span> <span class="cpf">&lt;torch/script.h&gt; // One-stop header.</span><span class="cp"></span>

<span class="cp">#include</span> <span class="cpf">&lt;iostream&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;memory&gt;</span><span class="cp"></span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="n">argv</span><span class="p">[])</span> <span class="p">{</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">argc</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">std</span><span class="o">::</span><span class="n">cerr</span> <span class="o">&lt;&lt;</span> <span class="s">"usage: example-app &lt;path-to-exported-script-module&gt;</span><span class="se">\n</span><span class="s">"</span><span class="p">;</span>
    <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="c1">// Deserialize the ScriptModule from a file using torch::jit::load().</span>
  <span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">torch</span><span class="o">::</span><span class="n">jit</span><span class="o">::</span><span class="n">script</span><span class="o">::</span><span class="n">Module</span><span class="o">&gt;</span> <span class="n">module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">::</span><span class="n">jit</span><span class="o">::</span><span class="n">load</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>

  <span class="n">assert</span><span class="p">(</span><span class="n">module</span> <span class="o">!=</span> <span class="k">nullptr</span><span class="p">);</span>
  <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"ok</span><span class="se">\n</span><span class="s">"</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">&lt;torch/script.h&gt;</span></code> header encompasses all relevant includes from the
LibTorch library necessary to run the example. Our application accepts the file
path to a serialized PyTorch <code class="docutils literal notranslate"><span class="pre">ScriptModule</span></code> as its only command line argument
and then proceeds to deserialize the module using the <code class="docutils literal notranslate"><span class="pre">torch::jit::load()</span></code>
function, which takes this file path as input. In return we receive a shared
pointer to a <code class="docutils literal notranslate"><span class="pre">torch::jit::script::Module</span></code>, the equivalent to a
<code class="docutils literal notranslate"><span class="pre">torch.jit.ScriptModule</span></code> in C++. For now, we only verify that this pointer is
not null. We will examine how to execute it in a moment.</p>
</div>
<div class="section" id="depending-on-libtorch-and-building-the-application">
<h3>Depending on LibTorch and Building the Application<a class="headerlink" href="#depending-on-libtorch-and-building-the-application" title="Permalink to this headline">¶</a></h3>
<p>Assume we stored the above code into a file called <code class="docutils literal notranslate"><span class="pre">example-app.cpp</span></code>. A
minimal <code class="docutils literal notranslate"><span class="pre">CMakeLists.txt</span></code> to build it could look as simple as:</p>
<div class="highlight-cmake notranslate"><div class="highlight"><pre><span></span><span class="nb">cmake_minimum_required</span><span class="p">(</span><span class="s">VERSION</span> <span class="s">3.0</span> <span class="s">FATAL_ERROR</span><span class="p">)</span>
<span class="nb">project</span><span class="p">(</span><span class="s">custom_ops</span><span class="p">)</span>

<span class="nb">find_package</span><span class="p">(</span><span class="s">Torch</span> <span class="s">REQUIRED</span><span class="p">)</span>

<span class="nb">add_executable</span><span class="p">(</span><span class="s">example-app</span> <span class="s">example-app.cpp</span><span class="p">)</span>
<span class="nb">target_link_libraries</span><span class="p">(</span><span class="s">example-app</span> <span class="s2">"${TORCH_LIBRARIES}"</span><span class="p">)</span>
<span class="nb">set_property</span><span class="p">(</span><span class="s">TARGET</span> <span class="s">example-app</span> <span class="s">PROPERTY</span> <span class="s">CXX_STANDARD</span> <span class="s">11</span><span class="p">)</span>
</pre></div>
</div>
<p>The last thing we need to build the example application is the LibTorch
distribution. You can always grab the latest stable release from the <a class="reference external" href="https://pytorch.org/">download
page</a> on the PyTorch website. If you download and unzip
the latest archive, you should receive a folder with the following directory
structure:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>libtorch/
  bin/
  include/
  lib/
  share/
</pre></div>
</div>
<ul class="simple">
<li>The <code class="docutils literal notranslate"><span class="pre">lib/</span></code> folder contains the shared libraries you must link against,</li>
<li>The <code class="docutils literal notranslate"><span class="pre">include/</span></code> folder contains header files your program will need to include,</li>
<li>The <code class="docutils literal notranslate"><span class="pre">share/</span></code> folder contains the necessary CMake configuration to enable the simple <code class="docutils literal notranslate"><span class="pre">find_package(Torch)</span></code> command above.</li>
</ul>
<div class="admonition tip">
<p class="first admonition-title">Tip</p>
<p class="last">On Windows, debug and release builds are not ABI-compatible. If you plan to
build your project in debug mode, please try the debug version of LibTorch.</p>
</div>
<p>The last step is building the application. For this, assume our example
directory is laid out like this:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>example-app/
  CMakeLists.txt
  example-app.cpp
</pre></div>
</div>
<p>We can now run the following commands to build the application from within the
<code class="docutils literal notranslate"><span class="pre">example-app/</span></code> folder:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>mkdir build
<span class="nb">cd</span> build
cmake -DCMAKE_PREFIX_PATH<span class="o">=</span>/path/to/libtorch ..
make
</pre></div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">/path/to/libtorch</span></code> should be the full path to the unzipped LibTorch
distribution. If all goes well, it will look something like this:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>root@4b5a67132e81:/example-app# mkdir build
root@4b5a67132e81:/example-app# <span class="nb">cd</span> build
root@4b5a67132e81:/example-app/build# cmake -DCMAKE_PREFIX_PATH<span class="o">=</span>/path/to/libtorch ..
-- The C compiler identification is GNU <span class="m">5</span>.4.0
-- The CXX compiler identification is GNU <span class="m">5</span>.4.0
-- Check <span class="k">for</span> working C compiler: /usr/bin/cc
-- Check <span class="k">for</span> working C compiler: /usr/bin/cc -- works
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - <span class="k">done</span>
-- Detecting C compile features
-- Detecting C compile features - <span class="k">done</span>
-- Check <span class="k">for</span> working CXX compiler: /usr/bin/c++
-- Check <span class="k">for</span> working CXX compiler: /usr/bin/c++ -- works
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - <span class="k">done</span>
-- Detecting CXX compile features
-- Detecting CXX compile features - <span class="k">done</span>
-- Looking <span class="k">for</span> pthread.h
-- Looking <span class="k">for</span> pthread.h - found
-- Looking <span class="k">for</span> pthread_create
-- Looking <span class="k">for</span> pthread_create - not found
-- Looking <span class="k">for</span> pthread_create in pthreads
-- Looking <span class="k">for</span> pthread_create in pthreads - not found
-- Looking <span class="k">for</span> pthread_create in pthread
-- Looking <span class="k">for</span> pthread_create in pthread - found
-- Found Threads: TRUE
-- Configuring <span class="k">done</span>
-- Generating <span class="k">done</span>
-- Build files have been written to: /example-app/build
root@4b5a67132e81:/example-app/build# make
Scanning dependencies of target example-app
<span class="o">[</span> <span class="m">50</span>%<span class="o">]</span> Building CXX object CMakeFiles/example-app.dir/example-app.cpp.o
<span class="o">[</span><span class="m">100</span>%<span class="o">]</span> Linking CXX executable example-app
<span class="o">[</span><span class="m">100</span>%<span class="o">]</span> Built target example-app
</pre></div>
</div>
<p>If we supply the path to the serialized <code class="docutils literal notranslate"><span class="pre">ResNet18</span></code> model we created earlier
to the resulting <code class="docutils literal notranslate"><span class="pre">example-app</span></code> binary, we should be rewarded with a friendly
“ok”:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>root@4b5a67132e81:/example-app/build# ./example-app model.pt
ok
</pre></div>
</div>
</div>
</div>
<div class="section" id="step-4-executing-the-script-module-in-c">
<h2>Step 4: Executing the Script Module in C++<a class="headerlink" href="#step-4-executing-the-script-module-in-c" title="Permalink to this headline">¶</a></h2>
<p>Having successfully loaded our serialized <code class="docutils literal notranslate"><span class="pre">ResNet18</span></code> in C++, we are now just a
couple lines of code away from executing it! Let’s add those lines to our C++
application’s <code class="docutils literal notranslate"><span class="pre">main()</span></code> function:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// Create a vector of inputs.</span>
<span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">torch</span><span class="o">::</span><span class="n">jit</span><span class="o">::</span><span class="n">IValue</span><span class="o">&gt;</span> <span class="n">inputs</span><span class="p">;</span>
<span class="n">inputs</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">ones</span><span class="p">({</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">}));</span>

<span class="c1">// Execute the model and turn its output into a tensor.</span>
<span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">output</span> <span class="o">=</span> <span class="n">module</span><span class="o">-&gt;</span><span class="n">forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">).</span><span class="n">toTensor</span><span class="p">();</span>

<span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">output</span><span class="p">.</span><span class="n">slice</span><span class="p">(</span><span class="cm">/*dim=*/</span><span class="mi">1</span><span class="p">,</span> <span class="cm">/*start=*/</span><span class="mi">0</span><span class="p">,</span> <span class="cm">/*end=*/</span><span class="mi">5</span><span class="p">)</span> <span class="o">&lt;&lt;</span> <span class="sc">'\n'</span><span class="p">;</span>
</pre></div>
</div>
<p>The first two lines set up the inputs to our model. We create a vector of
<code class="docutils literal notranslate"><span class="pre">torch::jit::IValue</span></code> (a type-erased value type <code class="docutils literal notranslate"><span class="pre">script::Module</span></code> methods
accept and return) and add a single input. To create the input tensor, we use
<code class="docutils literal notranslate"><span class="pre">torch::ones()</span></code>, the equivalent to <code class="docutils literal notranslate"><span class="pre">torch.ones</span></code> in the C++ API.  We then
run the <code class="docutils literal notranslate"><span class="pre">script::Module</span></code>’s <code class="docutils literal notranslate"><span class="pre">forward</span></code> method, passing it the input vector we
created. In return we get a new <code class="docutils literal notranslate"><span class="pre">IValue</span></code>, which we convert to a tensor by
calling <code class="docutils literal notranslate"><span class="pre">toTensor()</span></code>.</p>
<div class="admonition tip">
<p class="first admonition-title">Tip</p>
<p class="last">To learn more about functions like <code class="docutils literal notranslate"><span class="pre">torch::ones</span></code> and the PyTorch C++ API in
general, refer to its documentation at <a class="reference external" href="https://pytorch.org/cppdocs">https://pytorch.org/cppdocs</a>. The
PyTorch C++ API provides near feature parity with the Python API, allowing
you to further manipulate and process tensors just like in Python.</p>
</div>
<p>In the last line, we print the first five entries of the output. Since we
supplied the same input to our model in Python earlier in this tutorial, we
should ideally see the same output. Let’s try it out by re-compiling our
application and running it with the same serialized model:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>root@4b5a67132e81:/example-app/build# make
Scanning dependencies of target example-app
<span class="o">[</span> <span class="m">50</span>%<span class="o">]</span> Building CXX object CMakeFiles/example-app.dir/example-app.cpp.o
<span class="o">[</span><span class="m">100</span>%<span class="o">]</span> Linking CXX executable example-app
<span class="o">[</span><span class="m">100</span>%<span class="o">]</span> Built target example-app
root@4b5a67132e81:/example-app/build# ./example-app model.pt
-0.2698 -0.0381  <span class="m">0</span>.4023 -0.3010 -0.0448
<span class="o">[</span> Variable<span class="o">[</span>CPUFloatType<span class="o">]{</span><span class="m">1</span>,5<span class="o">}</span> <span class="o">]</span>
</pre></div>
</div>
<p>For reference, the output in Python previously was:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.2698</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0381</span><span class="p">,</span>  <span class="mf">0.4023</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3010</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0448</span><span class="p">],</span> <span class="n">grad_fn</span><span class="o">=&lt;</span><span class="n">SliceBackward</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
<p>Looks like a good match!</p>
<div class="admonition tip">
<p class="first admonition-title">Tip</p>
<p class="last">To move your model to GPU memory, you can write <code class="docutils literal notranslate"><span class="pre">model-&gt;to(at::kCUDA);</span></code>.
Make sure the inputs to a model living in CUDA memory are also in CUDA memory
by calling <code class="docutils literal notranslate"><span class="pre">tensor.to(at::kCUDA)</span></code>, which will return a new tensor in CUDA
memory.</p>
</div>
</div>
<div class="section" id="step-5-getting-help-and-exploring-the-api">
<h2>Step 5: Getting Help and Exploring the API<a class="headerlink" href="#step-5-getting-help-and-exploring-the-api" title="Permalink to this headline">¶</a></h2>
<p>This tutorial has hopefully equipped you with a general understanding of a
PyTorch model’s path from Python to C++. With the concepts described in this
tutorial, you should be able to go from a vanilla, “eager” PyTorch model, to a
compiled <code class="docutils literal notranslate"><span class="pre">ScriptModule</span></code> in Python, to a serialized file on disk and – to
close the loop – to an executable <code class="docutils literal notranslate"><span class="pre">script::Module</span></code> in C++.</p>
<p>Of course, there are many concepts we did not cover. For example, you may find
yourself wanting to extend your <code class="docutils literal notranslate"><span class="pre">ScriptModule</span></code> with a custom operator
implemented in C++ or CUDA, and executing this custom operator inside your
<code class="docutils literal notranslate"><span class="pre">ScriptModule</span></code> loaded in your pure C++ production environment. The good news
is: this is possible, and well supported! For now, you can explore <a class="reference external" href="https://github.com/pytorch/pytorch/tree/master/test/custom_operator">this</a> folder
for examples, and we will follow up with a tutorial shortly. In the time being,
the following links may be generally helpful:</p>
<ul class="simple">
<li>The Torch Script reference: <a class="reference external" href="https://pytorch.org/docs/master/jit.html">https://pytorch.org/docs/master/jit.html</a></li>
<li>The PyTorch C++ API documentation: <a class="reference external" href="https://pytorch.org/cppdocs/">https://pytorch.org/cppdocs/</a></li>
<li>The PyTorch Python API documentation: <a class="reference external" href="https://pytorch.org/docs/">https://pytorch.org/docs/</a></li>
</ul>
<p>As always, if you run into any problems or have questions, you can use our
<a class="reference external" href="https://discuss.pytorch.org/">forum</a> or <a class="reference external" href="https://github.com/pytorch/pytorch/issues">GitHub issues</a> to get in touch.</p>
</div>
</div>
</article>
</div>
<footer>
<div aria-label="footer navigation" class="rst-footer-buttons" role="navigation">
<a accesskey="n" class="btn btn-neutral float-right" href="cpp_frontend.html" rel="next" title="Using the PyTorch C++ Frontend">Next <img class="next-page" src="../_static/images/chevron-right-orange.svg"/></a>
<a accesskey="p" class="btn btn-neutral" href="ONNXLive.html" rel="prev" title="ONNX Live Tutorial"><img class="previous-page" src="../_static/images/chevron-right-orange.svg"/> Previous</a>
</div>
<hr/>
<div role="contentinfo">
<p>
        © Copyright 2017, PyTorch.

    </p>
</div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
</div>
</div>
<div class="pytorch-content-right" id="pytorch-content-right">
<div class="pytorch-right-menu" id="pytorch-right-menu">
<div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
<ul>
<li><a class="reference internal" href="#">Loading a PyTorch Model in C++</a><ul>
<li><a class="reference internal" href="#step-1-converting-your-pytorch-model-to-torch-script">Step 1: Converting Your PyTorch Model to Torch Script</a><ul>
<li><a class="reference internal" href="#converting-to-torch-script-via-tracing">Converting to Torch Script via Tracing</a></li>
<li><a class="reference internal" href="#converting-to-torch-script-via-annotation">Converting to Torch Script via Annotation</a></li>
</ul>
</li>
<li><a class="reference internal" href="#step-2-serializing-your-script-module-to-a-file">Step 2: Serializing Your Script Module to a File</a></li>
<li><a class="reference internal" href="#step-3-loading-your-script-module-in-c">Step 3: Loading Your Script Module in C++</a><ul>
<li><a class="reference internal" href="#a-minimal-c-application">A Minimal C++ Application</a></li>
<li><a class="reference internal" href="#depending-on-libtorch-and-building-the-application">Depending on LibTorch and Building the Application</a></li>
</ul>
</li>
<li><a class="reference internal" href="#step-4-executing-the-script-module-in-c">Step 4: Executing the Script Module in C++</a></li>
<li><a class="reference internal" href="#step-5-getting-help-and-exploring-the-api">Step 5: Getting Help and Exploring the API</a></li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</section>
</div>
<script type="text/javascript">
           var DOCUMENTATION_OPTIONS = {
               URL_ROOT:'../',
               VERSION:'1.0.0',
               LANGUAGE:'None',
               COLLAPSE_INDEX:false,
               FILE_SUFFIX:'.html',
               HAS_SOURCE:  true,
               SOURCELINK_SUFFIX: '.txt'
           };
       </script>
<script src="../_static/jquery.js" type="text/javascript"></script>
<script src="../_static/underscore.js" type="text/javascript"></script>
<script src="../_static/doctools.js" type="text/javascript"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<script src="../_static/js/vendor/popper.min.js" type="text/javascript"></script>
<script src="../_static/js/vendor/bootstrap.min.js" type="text/javascript"></script>
<script src="../_static/js/theme.js" type="text/javascript"></script>
<script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-90545585-2', 'auto');
  ga('send', 'pageview');

</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"></script>
<script>

  window.dataLayer = window.dataLayer || [];

  function gtag(){dataLayer.push(arguments);}

  gtag('js', new Date());
  gtag('config', 'UA-117752657-2');

</script>
<script>
  !function(f,b,e,v,n,t,s)
  {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
  n.callMethod.apply(n,arguments):n.queue.push(arguments)};
  if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
  n.queue=[];t=b.createElement(e);t.async=!0;
  t.src=v;s=b.getElementsByTagName(e)[0];
  s.parentNode.insertBefore(t,s)}(window,document,'script',
  'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');

  $("[data-behavior='call-to-action-event']").on('click', function(){
    fbq('trackCustom', "Download", {
      tutorialTitle: $('h1:first').text(),
      downloadLink: this.href,
      tutorialLink: window.location.href,
      downloadTitle: $(this).attr("data-response")
    });
    ga('send', {
      hitType: 'event',
      eventCategory: 'Download',
      eventAction: 'click',
      eventLabel: $(this).attr("data-response")
    });
   });

   $("[data-behavior='was-this-helpful-event']").on('click', function(){
    $(".helpful-question").hide();
    $(".was-helpful-thank-you").show();
    fbq('trackCustom', "Was this Helpful?", {
      tutorialLink: window.location.href,
      tutorialTitle: $('h1:first').text(),
      helpful: $(this).attr("data-response")
    });
    ga('send', {
      hitType: 'event',
      eventCategory: 'Was this Helpful?',
      eventAction: 'click',
      eventLabel: $(this).attr("data-response")
    });
   });

   if (location.pathname == "/") {
     $(".helpful-container").hide();
     $(".hr-bottom").hide();
   }
</script>
<noscript>
<img height="1" src="https://www.facebook.com/tr?id=243028289693773&amp;ev=PageView
  &amp;noscript=1" width="1">
</img></noscript>
<img alt="" height="1" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0" style="border-style:none;" width="1">
<!-- Begin Footer -->
<div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
<div class="container">
<div class="row">
<div class="col-md-4 text-center">
<h2>Docs</h2>
<p>Access comprehensive developer documentation for PyTorch</p>
<a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
</div>
<div class="col-md-4 text-center">
<h2>Tutorials</h2>
<p>Get in-depth tutorials for beginners and advanced developers</p>
<a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
</div>
<div class="col-md-4 text-center">
<h2>Resources</h2>
<p>Find development resources and get your questions answered</p>
<a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
</div>
</div>
</div>
</div>
<footer class="site-footer">
<div class="container footer-container">
<div class="footer-logo-wrapper">
<a class="footer-logo" href="https://pytorch.org/"></a>
</div>
<div class="footer-links-wrapper">
<div class="footer-links-col">
<ul>
<li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
<li><a href="https://pytorch.org/get-started">Get Started</a></li>
<li><a href="https://pytorch.org/features">Features</a></li>
<li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
<li><a href="https://pytorch.org/blog/">Blog</a></li>
<li><a href="https://pytorch.org/resources">Resources</a></li>
</ul>
</div>
<div class="footer-links-col">
<ul>
<li class="list-title"><a href="https://pytorch.org/support">Support</a></li>
<li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
<li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
<li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
<li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
<li><a href="https://pytorch.slack.com" target="_blank">Slack</a></li>
<li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md" target="_blank">Contributing</a></li>
</ul>
</div>
<div class="footer-links-col follow-us-col">
<ul>
<li class="list-title">Follow Us</li>
<li>
<div id="mc_embed_signup">
<form action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&amp;id=91d0dccd39" class="email-subscribe-form validate" id="mc-embedded-subscribe-form" method="post" name="mc-embedded-subscribe-form" novalidate="" target="_blank">
<div class="email-subscribe-form-fields-wrapper" id="mc_embed_signup_scroll">
<div class="mc-field-group">
<label for="mce-EMAIL" style="display:none;">Email Address</label>
<input class="required email" id="mce-EMAIL" name="EMAIL" placeholder="Email Address" type="email" value=""/>
</div>
<div class="clear" id="mce-responses">
<div class="response" id="mce-error-response" style="display:none"></div>
<div class="response" id="mce-success-response" style="display:none"></div>
</div> <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
<div aria-hidden="true" style="position: absolute; left: -5000px;"><input name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" type="text" value=""/></div>
<div class="clear">
<input class="button email-subscribe-button" id="mc-embedded-subscribe" name="subscribe" type="submit" value=""/>
</div>
</div>
</form>
</div>
</li>
</ul>
<div class="footer-social-icons">
<a class="facebook" href="https://www.facebook.com/pytorch" target="_blank"></a>
<a class="twitter" href="https://twitter.com/pytorch" target="_blank"></a>
</div>
</div>
</div>
</div>
</footer>
<!-- End Footer -->
<!-- Begin Mobile Menu -->
<div class="mobile-main-menu">
<div class="container-fluid">
<div class="container">
<div class="mobile-main-menu-header-container">
<a aria-label="PyTorch" class="header-logo" href="https://pytorch.org/"></a>
<a class="main-menu-close-button" data-behavior="close-mobile-menu" href="#"></a>
</div>
</div>
</div>
<div class="mobile-main-menu-links-container">
<div class="main-menu">
<ul>
<li>
<a href="#">Get Started</a>
</li>
<li>
<a href="#">Features</a>
</li>
<li>
<a href="#">Ecosystem</a>
</li>
<li>
<a href="https://pytorch.org/blog/">Blog</a>
</li>
<li class="active">
<a href="https://pytorch.org/tutorials">Tutorials</a>
</li>
<li>
<a href="https://pytorch.org/docs/stable/index.html">Docs</a>
</li>
<li>
<a href="https://pytorch.org/resources">Resources</a>
</li>
<li>
<a href="https://github.com/pytorch/pytorch">Github</a>
</li>
</ul>
</div>
</div>
</div>
<!-- End Mobile Menu -->
<script src="../_static/js/vendor/anchor.min.js" type="text/javascript"></script>
<script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</img></body>
</html>