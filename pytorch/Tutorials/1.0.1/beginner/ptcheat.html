
<!DOCTYPE html>

<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"> <!--<![endif]-->
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>PyTorch Cheat Sheet — PyTorch Tutorials 1.0.1 documentation</title>
<link href="../_static/css/theme.css" rel="stylesheet" type="text/css"/>
<!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
<link href="../_static/gallery.css" rel="stylesheet" type="text/css"/>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<script src="../_static/js/modernizr.min.js"></script>
</head>
<div class="container-fluid header-holder tutorials-header" id="header-holder">
<div class="container">
<div class="header-container">
<a aria-label="PyTorch" class="header-logo" href="https://pytorch.org/"></a>
<div class="main-menu">
<ul>
<li>
<a href="https://pytorch.org/get-started">Get Started</a>
</li>
<li>
<a href="https://pytorch.org/features">Features</a>
</li>
<li>
<a href="https://pytorch.org/ecosystem">Ecosystem</a>
</li>
<li>
<a href="https://pytorch.org/blog/">Blog</a>
</li>
<li class="active">
<a href="https://pytorch.org/tutorials">Tutorials</a>
</li>
<li>
<a href="https://pytorch.org/docs/stable/index.html">Docs</a>
</li>
<li>
<a href="https://pytorch.org/resources">Resources</a>
</li>
<li>
<a href="https://github.com/pytorch/pytorch">Github</a>
</li>
</ul>
</div>
<a class="main-menu-open-button" data-behavior="open-mobile-menu" href="#"></a>
</div>
</div>
</div>
<body class="pytorch-body">
<div class="table-of-contents-link-wrapper">
<span>Table of Contents</span>
<a class="toggle-table-of-contents" data-behavior="toggle-table-of-contents" href="#"></a>
</div>
<nav class="pytorch-left-menu" data-toggle="wy-nav-shift" id="pytorch-left-menu">
<div class="pytorch-side-scroll">
<div aria-label="main navigation" class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation">
<div class="pytorch-left-menu-search">
<div class="version">
                  1.0.1
                </div>
<div role="search">
<form action="../search.html" class="wy-form" id="rtd-search-form" method="get">
<input name="q" placeholder="Search Tutorials" type="text"/>
<input name="check_keywords" type="hidden" value="yes"/>
<input name="area" type="hidden" value="default"/>
</form>
</div>
</div>
<p class="caption"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="deep_learning_60min_blitz.html">Deep Learning with PyTorch: A 60 Minute Blitz</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_loading_tutorial.html">Data Loading and Processing Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="pytorch_with_examples.html">Learning PyTorch with Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="transfer_learning_tutorial.html">Transfer Learning Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy_seq2seq_hybrid_frontend_tutorial.html">Deploying a Seq2Seq Model with the Hybrid Frontend</a></li>
<li class="toctree-l1"><a class="reference internal" href="saving_loading_models.html">Saving and Loading Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn_tutorial.html">What is <cite>torch.nn</cite> <em>really</em>?</a></li>
</ul>
<p class="caption"><span class="caption-text">Image</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/torchvision_tutorial.html">TorchVision 0.3 Object Detection Finetuning Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="finetuning_torchvision_models_tutorial.html">Finetuning Torchvision Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/spatial_transformer_tutorial.html">Spatial Transformer Networks Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/neural_style_tutorial.html">Neural Transfer Using PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="fgsm_tutorial.html">Adversarial Example Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/super_resolution_with_caffe2.html">Transfering a Model from PyTorch to Caffe2 and Mobile using ONNX</a></li>
</ul>
<p class="caption"><span class="caption-text">Text</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="chatbot_tutorial.html">Chatbot Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html">Generating Names with a Character-Level RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html">Classifying Names with a Character-Level RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="deep_learning_nlp_tutorial.html">Deep Learning for NLP with Pytorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html">Translation with a Sequence to Sequence Network and Attention</a></li>
</ul>
<p class="caption"><span class="caption-text">Generative</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dcgan_faces_tutorial.html">DCGAN Tutorial</a></li>
</ul>
<p class="caption"><span class="caption-text">Reinforcement Learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html">Reinforcement Learning (DQN) Tutorial</a></li>
</ul>
<p class="caption"><span class="caption-text">Extending PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced/numpy_extensions_tutorial.html">Creating Extensions Using numpy and scipy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_extension.html">Custom C++ and CUDA Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/torch_script_custom_ops.html">Extending TorchScript with Custom C++ Operators</a></li>
</ul>
<p class="caption"><span class="caption-text">Production Usage</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/model_parallel_tutorial.html">Model Parallel Best Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/ddp_tutorial.html">Getting Started with Distributed Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dist_tuto.html">Writing Distributed Applications with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="aws_distributed_training_tutorial.html">PyTorch 1.0 Distributed Trainer with Amazon AWS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/ONNXLive.html">ONNX Live Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_export.html">Loading a PyTorch Model in C++</a></li>
</ul>
<p class="caption"><span class="caption-text">PyTorch in Other Languages</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_frontend.html">Using the PyTorch C++ Frontend</a></li>
</ul>
</div>
</div>
</nav>
<div class="pytorch-container">
<div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
<div class="pytorch-breadcrumbs-wrapper">
<div aria-label="breadcrumbs navigation" role="navigation">
<ul class="pytorch-breadcrumbs">
<li>
<a href="../index.html">
          
            Tutorials
          
        </a> &gt;
      </li>
<li>PyTorch Cheat Sheet</li>
<li class="pytorch-breadcrumbs-aside">
<a href="../_sources/beginner/ptcheat.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"/></a>
</li>
</ul>
</div>
</div>
<div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
</div>
<section class="pytorch-content-wrap" data-toggle="wy-nav-shift" id="pytorch-content-wrap">
<div class="pytorch-content-left">
<div class="rst-content">
<div class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
<article class="pytorch-article" id="pytorch-article" itemprop="articleBody">
<div class="section" id="pytorch-cheat-sheet">
<h1>PyTorch Cheat Sheet<a class="headerlink" href="#pytorch-cheat-sheet" title="Permalink to this headline">¶</a></h1>
<div class="section" id="imports">
<h2>Imports<a class="headerlink" href="#imports" title="Permalink to this headline">¶</a></h2>
<div class="section" id="general">
<h3>General<a class="headerlink" href="#general" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>                                        <span class="c1"># root package</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">Dataloader</span>    <span class="c1"># dataset representation and loading</span>
</pre></div>
</div>
</div>
<div class="section" id="neural-network-api">
<h3>Neural Network API<a class="headerlink" href="#neural-network-api" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch.autograd</span> <span class="kn">as</span> <span class="nn">autograd</span>         <span class="c1"># computation graph</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>       <span class="c1"># variable node in computation graph</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="kn">as</span> <span class="nn">nn</span>                     <span class="c1"># neural networks</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="kn">as</span> <span class="nn">F</span>           <span class="c1"># layers, activations and more</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="kn">as</span> <span class="nn">optim</span>               <span class="c1"># optimizers e.g. gradient descent, ADAM, etc.</span>
<span class="kn">from</span> <span class="nn">torch.jit</span> <span class="kn">import</span> <span class="n">script</span><span class="p">,</span> <span class="n">trace</span>       <span class="c1"># hybrid frontend decorator and tracing jit</span>
</pre></div>
</div>
<p>See <a class="reference external" href="https://pytorch.org/docs/stable/autograd.html">autograd</a>,
<a class="reference external" href="https://pytorch.org/docs/stable/nn.html">nn</a>,
<a class="reference external" href="https://pytorch.org/docs/stable/nn.html#torch-nn-functional">functional</a>
and <a class="reference external" href="https://pytorch.org/docs/stable/optim.html">optim</a></p>
</div>
<div class="section" id="hybrid-frontend">
<h3>Hybrid frontend<a class="headerlink" href="#hybrid-frontend" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">()</span>         <span class="c1"># takes your module or function and an example</span>
                          <span class="c1"># data input, and traces the computational steps</span>
                          <span class="c1"># that the data encounters as it progresses through the model</span>

<span class="nd">@script</span>                   <span class="c1"># decorator used to indicate data-dependent</span>
                          <span class="c1"># control flow within the code being traced</span>
</pre></div>
</div>
<p>See <a class="reference external" href="https://pytorch.org/docs/stable/hybridfrontend">hybrid frontend</a></p>
</div>
<div class="section" id="onnx">
<h3>ONNX<a class="headerlink" href="#onnx" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dummy</span> <span class="n">data</span><span class="p">,</span> <span class="n">xxxx</span><span class="o">.</span><span class="n">proto</span><span class="p">)</span>       <span class="c1"># exports an ONNX formatted</span>
                                                       <span class="c1"># model using a trained model, dummy</span>
                                                       <span class="c1"># data and the desired file name</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"alexnet.proto"</span><span class="p">)</span>                     <span class="c1"># load an ONNX model</span>
<span class="n">onnx</span><span class="o">.</span><span class="n">checker</span><span class="o">.</span><span class="n">check_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>                        <span class="c1"># check that the model</span>
                                                       <span class="c1"># IR is well formed</span>

<span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">printable_graph</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>               <span class="c1"># print a human readable</span>
                                                       <span class="c1"># representation of the graph</span>
</pre></div>
</div>
<p>See <a class="reference external" href="https://pytorch.org/docs/stable/onnx.html">onnx</a></p>
</div>
<div class="section" id="vision">
<h3>Vision<a class="headerlink" href="#vision" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">models</span><span class="p">,</span> <span class="n">transforms</span>     <span class="c1"># vision datasets,</span>
                                                         <span class="c1"># architectures &amp;</span>
                                                         <span class="c1"># transforms</span>

<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="kn">as</span> <span class="nn">transforms</span>              <span class="c1"># composable transforms</span>
</pre></div>
</div>
<p>See
<a class="reference external" href="https://pytorch.org/docs/stable/torchvision/index.html">torchvision</a></p>
</div>
<div class="section" id="distributed-training">
<h3>Distributed Training<a class="headerlink" href="#distributed-training" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch.distributed</span> <span class="kn">as</span> <span class="nn">dist</span>          <span class="c1"># distributed communication</span>
<span class="kn">from</span> <span class="nn">multiprocessing</span> <span class="kn">import</span> <span class="n">Process</span>       <span class="c1"># memory sharing processes</span>
</pre></div>
</div>
<p>See <a class="reference external" href="https://pytorch.org/docs/stable/distributed.html">distributed</a>
and
<a class="reference external" href="https://pytorch.org/docs/stable/multiprocessing.html">multiprocessing</a></p>
</div>
</div>
<div class="section" id="tensors">
<h2>Tensors<a class="headerlink" href="#tensors" title="Permalink to this headline">¶</a></h2>
<div class="section" id="creation">
<h3>Creation<a class="headerlink" href="#creation" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">size</span><span class="p">)</span>              <span class="c1"># tensor with independent N(0,1) entries</span>
<span class="n">torch</span><span class="o">.</span><span class="p">[</span><span class="n">ones</span><span class="o">|</span><span class="n">zeros</span><span class="p">](</span><span class="o">*</span><span class="n">size</span><span class="p">)</span>       <span class="c1"># tensor with all 1's [or 0's]</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>                 <span class="c1"># create tensor from [nested] list or ndarray L</span>
<span class="n">x</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>                       <span class="c1"># clone of x</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>           <span class="c1"># code wrap that stops autograd from tracking tensor history</span>
<span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span>              <span class="c1"># arg, when set to True, tracks computation</span>
                                <span class="c1"># history for future derivative calculations</span>
</pre></div>
</div>
<p>See <a class="reference external" href="https://pytorch.org/docs/stable/tensors.html">tensor</a></p>
</div>
<div class="section" id="dimensionality">
<h3>Dimensionality<a class="headerlink" href="#dimensionality" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>                              <span class="c1"># return tuple-like object of dimensions</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">tensor_seq</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>          <span class="c1"># concatenates tensors along dim</span>
<span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="o">...</span><span class="p">)</span>                       <span class="c1"># reshapes x into size (a,b,...)</span>
<span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">a</span><span class="p">)</span>                          <span class="c1"># reshapes x into size (b,a) for some b</span>
<span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">)</span>                      <span class="c1"># swaps dimensions a and b</span>
<span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="o">*</span><span class="n">dims</span><span class="p">)</span>                      <span class="c1"># permutes dimensions</span>
<span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>                      <span class="c1"># tensor with added axis</span>
<span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>                    <span class="c1"># (a,b,c) tensor -&gt; (a,b,1,c) tensor</span>
</pre></div>
</div>
<p>See <a class="reference external" href="https://pytorch.org/docs/stable/tensors.html">tensor</a></p>
</div>
<div class="section" id="algebra">
<h3>Algebra<a class="headerlink" href="#algebra" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">A</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>       <span class="c1"># matrix multiplication</span>
<span class="n">A</span><span class="o">.</span><span class="n">mv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>       <span class="c1"># matrix-vector multiplication</span>
<span class="n">x</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>         <span class="c1"># matrix transpose</span>
</pre></div>
</div>
<p>See <a class="reference external" href="https://pytorch.org/docs/stable/torch.html?highlight=mm#math-operations">math
operations</a></p>
</div>
<div class="section" id="gpu-usage">
<h3>GPU Usage<a class="headerlink" href="#gpu-usage" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span>                                 <span class="c1"># check for cuda</span>
<span class="n">x</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>                                                <span class="c1"># move x's data from</span>
                                                        <span class="c1"># CPU to GPU and return new object</span>

<span class="n">x</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>                                                 <span class="c1"># move x's data from GPU to CPU</span>
                                                        <span class="c1"># and return new object</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">args</span><span class="o">.</span><span class="n">disable_cuda</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span> <span class="c1"># device agnostic code</span>
    <span class="n">args</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">'cuda'</span><span class="p">)</span>                  <span class="c1"># and modularity</span>
<span class="k">else</span><span class="p">:</span>                                                   <span class="c1">#</span>
    <span class="n">args</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">'cpu'</span><span class="p">)</span>                   <span class="c1">#</span>

<span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>                                          <span class="c1"># recursively convert their</span>
                                                        <span class="c1"># parameters and buffers to</span>
                                                        <span class="c1"># device specific tensors</span>

<span class="n">mytensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>                                     <span class="c1"># copy your tensors to a device</span>
                                                        <span class="c1"># (gpu, cpu)</span>
</pre></div>
</div>
<p>See <a class="reference external" href="https://pytorch.org/docs/stable/cuda.html">cuda</a></p>
</div>
</div>
<div class="section" id="deep-learning">
<h2>Deep Learning<a class="headerlink" href="#deep-learning" title="Permalink to this headline">¶</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>                                <span class="c1"># fully connected layer from</span>
                                              <span class="c1"># m to n units</span>

<span class="n">nn</span><span class="o">.</span><span class="n">ConvXd</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">n</span><span class="p">,</span><span class="n">s</span><span class="p">)</span>                              <span class="c1"># X dimensional conv layer from</span>
                                              <span class="c1"># m to n channels where X⍷{1,2,3}</span>
                                              <span class="c1"># and the kernel size is s</span>

<span class="n">nn</span><span class="o">.</span><span class="n">MaxPoolXd</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>                               <span class="c1"># X dimension pooling layer</span>
                                              <span class="c1"># (notation as above)</span>

<span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm</span>                                  <span class="c1"># batch norm layer</span>
<span class="n">nn</span><span class="o">.</span><span class="n">RNN</span><span class="o">/</span><span class="n">LSTM</span><span class="o">/</span><span class="n">GRU</span>                               <span class="c1"># recurrent layers</span>
<span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>              <span class="c1"># dropout layer for any dimensional input</span>
<span class="n">nn</span><span class="o">.</span><span class="n">Dropout2d</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>            <span class="c1"># 2-dimensional channel-wise dropout</span>
<span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">num_embeddings</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>   <span class="c1"># (tensor-wise) mapping from</span>
                                              <span class="c1"># indices to embedding vectors</span>
</pre></div>
</div>
<p>See <a class="reference external" href="https://pytorch.org/docs/stable/nn.html">nn</a></p>
<div class="section" id="loss-functions">
<h3>Loss Functions<a class="headerlink" href="#loss-functions" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">nn</span><span class="o">.</span><span class="n">X</span> <span class="n">where</span> <span class="k">for</span> <span class="n">example</span> <span class="n">X</span> <span class="ow">is</span> <span class="o">...</span>       <span class="c1"># BCELoss, CrossEntropyLoss,</span>
                                      <span class="c1"># L1Loss, MSELoss, NLLLoss, SoftMarginLoss,</span>
                                      <span class="c1"># MultiLabelSoftMarginLoss, CosineEmbeddingLoss,</span>
                                      <span class="c1"># KLDivLoss, MarginRankingLoss, HingeEmbeddingLoss</span>
                                      <span class="c1"># or CosineEmbeddingLoss</span>
</pre></div>
</div>
<p>See <a class="reference external" href="https://pytorch.org/docs/stable/nn.html#loss-functions">loss
functions</a></p>
</div>
<div class="section" id="activation-functions">
<h3>Activation Functions<a class="headerlink" href="#activation-functions" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">nn</span><span class="o">.</span><span class="n">X</span> <span class="n">where</span> <span class="k">for</span> <span class="n">example</span> <span class="n">X</span> <span class="ow">is</span> <span class="o">...</span>       <span class="c1"># ReLU, ReLU6, ELU, SELU, PReLU, LeakyReLU,</span>
                                      <span class="c1"># Threshold, HardTanh, Sigmoid, Tanh,</span>
                                      <span class="c1"># LogSigmoid, Softplus, SoftShrink,</span>
                                      <span class="c1"># Softsign, TanhShrink, Softmin, Softmax,</span>
                                      <span class="c1"># Softmax2d or LogSoftmax</span>
</pre></div>
</div>
<p>See <a class="reference external" href="https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity">activation
functions</a></p>
</div>
<div class="section" id="optimizers">
<h3>Optimizers<a class="headerlink" href="#optimizers" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">opt</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">x</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="o">...</span><span class="p">)</span>      <span class="c1"># create optimizer</span>
<span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>                                  <span class="c1"># update weights</span>
<span class="n">optim</span><span class="o">.</span><span class="n">X</span> <span class="n">where</span> <span class="k">for</span> <span class="n">example</span> <span class="n">X</span> <span class="ow">is</span> <span class="o">...</span>          <span class="c1"># SGD, Adadelta, Adagrad, Adam,</span>
                                            <span class="c1"># SparseAdam, Adamax, ASGD,</span>
                                            <span class="c1"># LBFGS, RMSProp or Rprop</span>
</pre></div>
</div>
<p>See <a class="reference external" href="https://pytorch.org/docs/stable/optim.html">optimizers</a></p>
</div>
<div class="section" id="learning-rate-scheduling">
<h3>Learning rate scheduling<a class="headerlink" href="#learning-rate-scheduling" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">X</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span><span class="o">...</span><span class="p">)</span>      <span class="c1"># create lr scheduler</span>
<span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>                        <span class="c1"># update lr at start of epoch</span>
<span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">X</span> <span class="n">where</span> <span class="o">...</span>          <span class="c1"># LambdaLR, StepLR, MultiStepLR,</span>
                                        <span class="c1"># ExponentialLR or ReduceLROnPLateau</span>
</pre></div>
</div>
<p>See <a class="reference external" href="https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate">learning rate
scheduler</a></p>
</div>
</div>
<div class="section" id="data-utilities">
<h2>Data Utilities<a class="headerlink" href="#data-utilities" title="Permalink to this headline">¶</a></h2>
<div class="section" id="datasets">
<h3>Datasets<a class="headerlink" href="#datasets" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Dataset</span>                    <span class="c1"># abstract class representing dataset</span>
<span class="n">TensorDataset</span>              <span class="c1"># labelled dataset in the form of tensors</span>
<span class="n">Concat</span> <span class="n">Dataset</span>             <span class="c1"># concatenation of Datasets</span>
</pre></div>
</div>
<p>See
<a class="reference external" href="https://pytorch.org/docs/stable/data.html?highlight=dataset#torch.utils.data.Dataset">datasets</a></p>
</div>
<div class="section" id="dataloaders-and-datasamplers">
<h3>Dataloaders and DataSamplers<a class="headerlink" href="#dataloaders-and-datasamplers" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>      <span class="c1"># loads data batches agnostic</span>
                                            <span class="c1"># of structure of individual data points</span>

<span class="n">sampler</span><span class="o">.</span><span class="n">Sampler</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span><span class="o">...</span><span class="p">)</span>                <span class="c1"># abstract class dealing with</span>
                                            <span class="c1"># ways to sample from dataset</span>

<span class="n">sampler</span><span class="o">.</span><span class="n">XSampler</span> <span class="n">where</span> <span class="o">...</span>                  <span class="c1"># Sequential, Random, Subset,</span>
                                            <span class="c1"># WeightedRandom or Distributed</span>
</pre></div>
</div>
<p>See
<a class="reference external" href="https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader">dataloader</a></p>
</div>
<div class="section" id="also-see">
<h3>Also see<a class="headerlink" href="#also-see" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><a class="reference external" href="https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html">Deep Learning with PyTorch: A 60 Minute
Blitz</a>
<em>(pytorch.org)</em></li>
<li><a class="reference external" href="https://discuss.pytorch.org/">PyTorch Forums</a>
<em>(discuss.pytorch.org)</em></li>
<li><a class="reference external" href="https://github.com/wkentaro/pytorch-for-numpy-users">PyTorch for Numpy
users</a>
<em>(github.com/wkentaro/pytorch-for-numpy-users)</em></li>
</ul>
</div>
</div>
</div>
</article>
</div>
<footer>
<hr/>
<div role="contentinfo">
<p>
        © Copyright 2017, PyTorch.

    </p>
</div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
</div>
</div>
<div class="pytorch-content-right" id="pytorch-content-right">
<div class="pytorch-right-menu" id="pytorch-right-menu">
<div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
<ul>
<li><a class="reference internal" href="#">PyTorch Cheat Sheet</a><ul>
<li><a class="reference internal" href="#imports">Imports</a><ul>
<li><a class="reference internal" href="#general">General</a></li>
<li><a class="reference internal" href="#neural-network-api">Neural Network API</a></li>
<li><a class="reference internal" href="#hybrid-frontend">Hybrid frontend</a></li>
<li><a class="reference internal" href="#onnx">ONNX</a></li>
<li><a class="reference internal" href="#vision">Vision</a></li>
<li><a class="reference internal" href="#distributed-training">Distributed Training</a></li>
</ul>
</li>
<li><a class="reference internal" href="#tensors">Tensors</a><ul>
<li><a class="reference internal" href="#creation">Creation</a></li>
<li><a class="reference internal" href="#dimensionality">Dimensionality</a></li>
<li><a class="reference internal" href="#algebra">Algebra</a></li>
<li><a class="reference internal" href="#gpu-usage">GPU Usage</a></li>
</ul>
</li>
<li><a class="reference internal" href="#deep-learning">Deep Learning</a><ul>
<li><a class="reference internal" href="#loss-functions">Loss Functions</a></li>
<li><a class="reference internal" href="#activation-functions">Activation Functions</a></li>
<li><a class="reference internal" href="#optimizers">Optimizers</a></li>
<li><a class="reference internal" href="#learning-rate-scheduling">Learning rate scheduling</a></li>
</ul>
</li>
<li><a class="reference internal" href="#data-utilities">Data Utilities</a><ul>
<li><a class="reference internal" href="#datasets">Datasets</a></li>
<li><a class="reference internal" href="#dataloaders-and-datasamplers">Dataloaders and DataSamplers</a></li>
<li><a class="reference internal" href="#also-see">Also see</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</section>
</div>
<script type="text/javascript">
           var DOCUMENTATION_OPTIONS = {
               URL_ROOT:'../',
               VERSION:'1.0.1',
               LANGUAGE:'None',
               COLLAPSE_INDEX:false,
               FILE_SUFFIX:'.html',
               HAS_SOURCE:  true,
               SOURCELINK_SUFFIX: '.txt'
           };
       </script>
<script src="../_static/jquery.js" type="text/javascript"></script>
<script src="../_static/underscore.js" type="text/javascript"></script>
<script src="../_static/doctools.js" type="text/javascript"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<script src="../_static/js/vendor/popper.min.js" type="text/javascript"></script>
<script src="../_static/js/vendor/bootstrap.min.js" type="text/javascript"></script>
<script src="../_static/js/theme.js" type="text/javascript"></script>
<script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-90545585-2', 'auto');
  ga('send', 'pageview');

</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"></script>
<script>

  window.dataLayer = window.dataLayer || [];

  function gtag(){dataLayer.push(arguments);}

  gtag('js', new Date());
  gtag('config', 'UA-117752657-2');

</script>
<script>
  !function(f,b,e,v,n,t,s)
  {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
  n.callMethod.apply(n,arguments):n.queue.push(arguments)};
  if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
  n.queue=[];t=b.createElement(e);t.async=!0;
  t.src=v;s=b.getElementsByTagName(e)[0];
  s.parentNode.insertBefore(t,s)}(window,document,'script',
  'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');

  $("[data-behavior='call-to-action-event']").on('click', function(){
    fbq('trackCustom', "Download", {
      tutorialTitle: $('h1:first').text(),
      downloadLink: this.href,
      tutorialLink: window.location.href,
      downloadTitle: $(this).attr("data-response")
    });
    ga('send', {
      hitType: 'event',
      eventCategory: 'Download',
      eventAction: 'click',
      eventLabel: $(this).attr("data-response")
    });
   });

   $("[data-behavior='was-this-helpful-event']").on('click', function(){
    $(".helpful-question").hide();
    $(".was-helpful-thank-you").show();
    fbq('trackCustom', "Was this Helpful?", {
      tutorialLink: window.location.href,
      tutorialTitle: $('h1:first').text(),
      helpful: $(this).attr("data-response")
    });
    ga('send', {
      hitType: 'event',
      eventCategory: 'Was this Helpful?',
      eventAction: 'click',
      eventLabel: $(this).attr("data-response")
    });
   });

   if (location.pathname == "/") {
     $(".helpful-container").hide();
     $(".hr-bottom").hide();
   }
</script>
<noscript>
<img height="1" src="https://www.facebook.com/tr?id=243028289693773&amp;ev=PageView
  &amp;noscript=1" width="1">
</img></noscript>
<img alt="" height="1" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0" style="border-style:none;" width="1"/>
<!-- Begin Footer -->
<div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
<div class="container">
<div class="row">
<div class="col-md-4 text-center">
<h2>Docs</h2>
<p>Access comprehensive developer documentation for PyTorch</p>
<a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
</div>
<div class="col-md-4 text-center">
<h2>Tutorials</h2>
<p>Get in-depth tutorials for beginners and advanced developers</p>
<a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
</div>
<div class="col-md-4 text-center">
<h2>Resources</h2>
<p>Find development resources and get your questions answered</p>
<a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
</div>
</div>
</div>
</div>
<footer class="site-footer">
<div class="container footer-container">
<div class="footer-logo-wrapper">
<a class="footer-logo" href="https://pytorch.org/"></a>
</div>
<div class="footer-links-wrapper">
<div class="footer-links-col">
<ul>
<li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
<li><a href="https://pytorch.org/get-started">Get Started</a></li>
<li><a href="https://pytorch.org/features">Features</a></li>
<li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
<li><a href="https://pytorch.org/blog/">Blog</a></li>
<li><a href="https://pytorch.org/resources">Resources</a></li>
</ul>
</div>
<div class="footer-links-col">
<ul>
<li class="list-title"><a href="https://pytorch.org/support">Support</a></li>
<li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
<li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
<li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
<li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
<li><a href="https://pytorch.slack.com" target="_blank">Slack</a></li>
<li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md" target="_blank">Contributing</a></li>
</ul>
</div>
<div class="footer-links-col follow-us-col">
<ul>
<li class="list-title">Follow Us</li>
<li>
<div id="mc_embed_signup">
<form action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&amp;id=91d0dccd39" class="email-subscribe-form validate" id="mc-embedded-subscribe-form" method="post" name="mc-embedded-subscribe-form" novalidate="" target="_blank">
<div class="email-subscribe-form-fields-wrapper" id="mc_embed_signup_scroll">
<div class="mc-field-group">
<label for="mce-EMAIL" style="display:none;">Email Address</label>
<input class="required email" id="mce-EMAIL" name="EMAIL" placeholder="Email Address" type="email" value=""/>
</div>
<div class="clear" id="mce-responses">
<div class="response" id="mce-error-response" style="display:none"></div>
<div class="response" id="mce-success-response" style="display:none"></div>
</div> <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
<div aria-hidden="true" style="position: absolute; left: -5000px;"><input name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" type="text" value=""/></div>
<div class="clear">
<input class="button email-subscribe-button" id="mc-embedded-subscribe" name="subscribe" type="submit" value=""/>
</div>
</div>
</form>
</div>
</li>
</ul>
<div class="footer-social-icons">
<a class="facebook" href="https://www.facebook.com/pytorch" target="_blank"></a>
<a class="twitter" href="https://twitter.com/pytorch" target="_blank"></a>
</div>
</div>
</div>
</div>
</footer>
<!-- End Footer -->
<!-- Begin Mobile Menu -->
<div class="mobile-main-menu">
<div class="container-fluid">
<div class="container">
<div class="mobile-main-menu-header-container">
<a aria-label="PyTorch" class="header-logo" href="https://pytorch.org/"></a>
<a class="main-menu-close-button" data-behavior="close-mobile-menu" href="#"></a>
</div>
</div>
</div>
<div class="mobile-main-menu-links-container">
<div class="main-menu">
<ul>
<li>
<a href="#">Get Started</a>
</li>
<li>
<a href="#">Features</a>
</li>
<li>
<a href="#">Ecosystem</a>
</li>
<li>
<a href="https://pytorch.org/blog/">Blog</a>
</li>
<li class="active">
<a href="https://pytorch.org/tutorials">Tutorials</a>
</li>
<li>
<a href="https://pytorch.org/docs/stable/index.html">Docs</a>
</li>
<li>
<a href="https://pytorch.org/resources">Resources</a>
</li>
<li>
<a href="https://github.com/pytorch/pytorch">Github</a>
</li>
</ul>
</div>
</div>
</div>
<!-- End Mobile Menu -->
<script src="../_static/js/vendor/anchor.min.js" type="text/javascript"></script>
<script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>